{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 TensorFlow Lite: Conversion and Optimization\n",
    "\n",
    "This notebooks uses Tensorflow Lite to convert the previous designed and trained Keras models.\n",
    "For the moment, the notebook only enables the conversation in supported quantization (see the picture below).\n",
    "\n",
    "\n",
    "You can check the Appendix notebook `AXX-Exploring-TFL-Conversion.ipynb`, to explore all possible quantization in a systematic manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '00_README.ipynb'\n",
    "%run 'H02_TFL-Conversion.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Information\n",
    "\n",
    "[Converter Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter)\n",
    "\n",
    "[More Converter Documentation for TF 2.2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/index.md)\n",
    "\n",
    "[Tensorflow Blog about Integer Quantization](https://blog.tensorflow.org/2019/06/tensorflow-integer-quantization.html)\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/lite/performance/images/optimization.jpg\" style=\"width: 800px;\"/>\n",
    "\n",
    "#### More on quantizing with TF Lite\n",
    "- [Documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/quantization.md)\n",
    "- [Full integer quantization of weights and activations](https://www.tensorflow.org/lite/convert/quantization)\n",
    "- [Quantization Specification](https://www.tensorflow.org/lite/performance/quantization_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple models can be selected (shift-click) and collective converted and optimized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = widgets.SelectMultiple(\n",
    "    options=sorted(glob.glob(\"keras-model/*.h5\")),\n",
    "    description='Select model:',\n",
    "    layout=Layout(width='100%', height='200px')\n",
    ")\n",
    "display(model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first model\n",
    "tf_model_file = model_selection.value[0]\n",
    "tf_model = tf.keras.models.load_model(tf_model_file)\n",
    "\n",
    "# set model name\n",
    "model_name = get_tf_model_string(tf_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data_selection = widgets.Dropdown(\n",
    "    options=sorted(glob.glob(\"keras-model/*.py\")),\n",
    "    description='Select model:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "display(data_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_data = data_selection.value\n",
    "%run -i {tf_model_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model into working formats\n",
    "\n",
    "At this stage we have three conversation available:\n",
    "1. none: `float32`\n",
    "2. mixed: `int8` weights, `float32` activations\n",
    "3. full: `int8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _tf_model_file in model_selection.value:\n",
    "    _tf_model = tf.keras.models.load_model(_tf_model_file)\n",
    "    convert_tf_model(_tf_model, _tf_model_file, 'none', x_train_normalized[:1000])\n",
    "    convert_tf_model(_tf_model, _tf_model_file, 'mixed', x_train_normalized[:1000])\n",
    "    convert_tf_model(_tf_model, _tf_model_file, 'full', x_train_normalized[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filesize differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_model_files = glob.glob(f'./TFLite-model/*{model_name}*.tflite')\n",
    "unquantized_model_file = glob.glob(f'./TFLite-model/*{model_name}*Q-none.tflite')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tfl_model_file in tfl_model_files:\n",
    "    model_size, reduction = get_tfl_size(tfl_model_file, unquantized_model_file=unquantized_model_file)\n",
    "    print(f\"{tfl_model_file[15:]:<40}\" + \n",
    "          \"{:>20}\".format(\"%10d KiB\" %model_size) + \n",
    "          \"{:>20}\".format(\"(%.2f%% smaller)\" %reduction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using gzip\n",
    "This is interesting to explore potential savings when a pruned networked is used as `.tflite` files do not exploit the pruned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tfl_model_file in tfl_model_files:\n",
    "    model_size, reduction = get_tfl_size(tfl_model_file, gzip=True, unquantized_model_file=unquantized_model_file)\n",
    "    print(f\"{tfl_model_file[15:]:<40}\" + \n",
    "          \"{:>10}\".format(\"%10d KiB\" %model_size) + \n",
    "          \"{:>10}\".format(\"(%.2f%% smaller)\" %reduction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with TFLite Interpreter\n",
    "[Interpreter Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the model for the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original predictions & score (Keras model)\n",
    "tf_model_predictions = tf_model.predict(x=x_test_normalized)\n",
    "\n",
    "tf_model_accuracy = calc_accuracy(tf_model_predictions, y_test)\n",
    "tf_model_loss = loss_fn_crossentropy(y_test, tf_model_predictions).numpy()\n",
    "\n",
    "# score = tf_model.evaluate(x=x_test_normalized, y=y_test)\n",
    "# tf_model_loss = score[0]\n",
    "# tf_model_accuracy = score[1]\n",
    "\n",
    "# converted models\n",
    "for tfl_model_file in tfl_model_files:\n",
    "    print(f\"Evaluating {tfl_model_file}:\")\n",
    "    \n",
    "    tfl_model_predictions = tfl_predict(tfl_model_file, x=x_test_normalized)\n",
    "    tfl_model_accuracy = calc_accuracy(tfl_model_predictions, y_test)\n",
    "    \n",
    "    print(\"\\tOriginal (Keras) model accuracy:\\t\", tf_model_accuracy)\n",
    "    print(\"\\tTF Lite Model Accuracy:\\t\\t\\t\", tfl_model_accuracy)\n",
    "    \n",
    "    tfl_crossentropy_loss = loss_fn_crossentropy(y_test, tfl_model_predictions).numpy()\n",
    "    # tfl_meansquared_loss = loss_fn_meansquared(y_test, tfl_model_predictions).numpy()\n",
    "\n",
    "    print(\"\\tOriginal (Keras) model cross entropy loss:\\t\", tf_model_loss)\n",
    "    print(\"\\tTF Lite Model cross entropy loss:\\t\\t\", tfl_crossentropy_loss)\n",
    "    \n",
    "    \n",
    "    # What's the error?\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(tf_model_predictions, tfl_model_predictions, decimal=2)\n",
    "    except AssertionError as err:\n",
    "        #print(f\"\\t{err}\")\n",
    "        pass\n",
    "\n",
    "        \n",
    "    print(\"________\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_accuracy(tfl_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert individual models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_files = glob.glob(f'./TFLite-model/*{model_name}*.tflite')\n",
    "tfl_model_dropdown = widgets.Dropdown(\n",
    "    options=tfl_files,\n",
    "    description='Converted Model:'\n",
    ")\n",
    "display(tfl_model_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate input and output details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl_model_file = tfl_model_dropdown.value\n",
    "\n",
    "input_details, output_details = get_tfl_details(tfl_model_file)\n",
    "\n",
    "print(\"\\ninput_details:\\n\", input_details)\n",
    "print(\"\\noutput_details:\\n\", output_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke selected model for a single random image from the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no = np.random.randint(x_test_normalized.shape[0])\n",
    "\n",
    "tfl_inference(tfl_model_file, x_test_normalized[image_no])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis with tflite_analyser\n",
    "Make sure to install [tflite_analyser](https://github.com/PeteBlackerThe3rd/tflite_analyser) and its dependencies and point to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/PeteBlackerThe3rd/tflite_analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 tflite_analyser/tflite_analyser.py {tfl_model_file} --all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
