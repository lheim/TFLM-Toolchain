{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Automated Batch Processing\n",
    "\n",
    "This notebook combines all the previous steps in an automated manner. It allows one to use a selection of `.tflite` models to be deployed on an MCU target, run benchmarking inference, collect the evaluation results, and save the results.\n",
    "\n",
    "Using this script one can evaluate the impact of optimizations like quantization, CMSIS-NN, compiler optimizations, FPUs, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported helper functions from 00_README.ipynb\n",
      "Imported all modules.\n",
      "\tTensorflow Version:  2.2.0\n",
      "\tNumpy Version:  1.19.0\n",
      "\tPandas Version:  1.0.5\n",
      "Imported helper functions from H01_Models.ipynb\n",
      "Imported helper functions from H02_TFL-Conversion.ipynb\n",
      "Imported helper functions from H03_TFLu.ipynb\n",
      "Imported helper functions from H04_MCU-Verification.ipynb\n"
     ]
    }
   ],
   "source": [
    "%run '00_README.ipynb'\n",
    "%run 'H01_Models.ipynb'\n",
    "%run 'H02_TFL-Conversion.ipynb'\n",
    "%run 'H03_TFLu.ipynb'\n",
    "%run 'H04_MCU-Verification.ipynb'\n",
    "%run 'H05_RocketLogger.ipynb'\n",
    "%run 'H06_Energy-Parser.ipynb'\n",
    "%run 'H10_Batch-Processing.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e93288d69724e5f8b50ace33488b050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select model:', options=('keras-model/01aA_LeNet-MNIST.h5', 'keras-model/01aW_LeNet-MNIS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tf_model_file = model_selection.value\n",
    "tf_model = tf.keras.models.load_model(tf_model_file)\n",
    "\n",
    "# set model name\n",
    "model_name = get_tf_model_string(tf_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230d662298934469bd7644c22a7d5d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select model:', layout=Layout(width='100%'), options=('keras-model/01a_LeNet-MNIST_data.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " data_selection = widgets.Dropdown(\n",
    "    options=sorted(glob.glob(\"keras-model/*.py\")),\n",
    "    description='Select model:',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "display(data_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input length is 576 and the output length 10\n"
     ]
    }
   ],
   "source": [
    "tf_model_data = data_selection.value\n",
    "%run -i {tf_model_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which converted model would you like to deploy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which quantizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb33963228f4d58b679262fd32003e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select model:', layout=Layout(height='200px', width='100%'), options=('TFLite-mode…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# todo: make this checkmarks\n",
    "display(tfl_model_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TFLite-model/01f_Depthwise-Conv_f-100_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-100_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-100_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-101_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-101_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-101_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-102_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-102_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-102_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-103_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-103_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-103_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-104_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-104_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-104_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-105_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-105_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-105_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-106_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-106_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-106_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-107_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-107_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-107_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-108_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-108_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-108_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-109_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-109_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-109_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-110_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-110_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-110_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-111_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-111_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-111_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-112_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-112_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-112_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-113_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-113_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-113_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-114_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-114_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-114_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-115_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-115_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-115_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-116_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-116_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-116_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-117_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-117_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-117_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-118_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-118_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-118_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-119_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-119_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-119_K-5_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-120_K-1_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-120_K-3_Q-full.tflite',\n",
       " 'TFLite-model/01f_Depthwise-Conv_f-120_K-5_Q-full.tflite')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfl_model_selections.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a base (default) model which will be used as a reference\n",
    "This is usually the non-optimized float32, float32 .tflite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_file = f'./TFLite-model/{model_name}_Q-none.tflite'\n",
    "basic_model_size = os.path.getsize(basic_model_file) / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target device and serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete verification or how much data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which optimizations?\n",
    "You can select multiple pr pressing `CTRL` and clicking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dfcd990a2145aeaf151cd3f2ad76cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select cmsis modes:', options=(('none', './TFLu_benchmark-model_mbed'), ('cmsis-nn…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e18c7431fa44a286fc03791151f25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select FPU modes:', options=(('FPU disabled', 0), ('FPU enabled', 1)), value=())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93c0ce24e9d4110abb316c3185c06c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select compiler options:', options=('-Ofast', '-Os'), value=())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cmsis_selections, fpu_selections, compiler_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update mbed according to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-loopable para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6849b5c7c043898e19f9b1debdbfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select targets:', options=('auto', 'NUCLEO_L496ZG', 'NUCLEO_F767ZI', '...'), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346ade1859c043b2a4906b939018ccba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=1000000.0, description='Baudrate', max=6.0, min=4.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33792fd602f4ae0a98f57848e03e3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Benchmark in cycles (instead of us)', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564ffe02ca8148cdade8201e6a9e56f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Benchmark with layer granularity (instead of a whole inference)', indent=Fa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cb6005a9a444f189fa6d5daf845c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Report the results of the inference via UART', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01b7660c4c743308ff7f8a0ad044ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Enabling custom input via UART (required for automated verification)', inden…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d05499ee24705ac2555361b61c13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Enable custom settings for an energy measurement', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_mcu = ''\n",
    "\n",
    "display(target_selections,\n",
    "        baudrate_slider,\n",
    "        cycles_selection,\n",
    "        layers_selection,\n",
    "        reporting_selection,\n",
    "        input_selection,\n",
    "        energy_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "# write constants which stay across the optimizations\n",
    "# like example pic\n",
    "# download mbed\n",
    "\n",
    "#for x\n",
    "#    patch_arena_size(mbed_dirs[mbed_dir], arena_size_kb)\n",
    "\n",
    "    \n",
    "# we dont write the constants as the constant includes the filename of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update all mpeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe / table for saving everything\n",
    "# create folder with all the individual savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-D INPUT_LENGTH=576 -D OUTPUT_LENGTH=10 -D BAUDRATE=1000000 -D BENCHMARK_LAYERS -D ENERGY_MEASUREMENT \n"
     ]
    }
   ],
   "source": [
    "arguments = set_compilation_macros(INPUT_LENGTH, OUTPUT_LENGTH, baudrate=int(baudrate_slider.value),\n",
    "           cycles=cycles_selection.value, layers=layers_selection.value, \n",
    "            reporting=reporting_selection.value, \n",
    "           manual_input=input_selection.value, energy=energy_selection.value)\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Flashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating repository ...\n",
      "Saved working directory and index state WIP on master: a54197a layer gpio now toggles\n",
      "Already up to date.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if 'cmsis-nn' in cmsis_selections.value:\n",
    "    update_mbed_project()\n",
    "    mbed_dir = './TFLu_benchmark-model_mbed_cmsis-nn'\n",
    "else:\n",
    "    update_mbed_project(cmsis=False)\n",
    "    mbed_dir = './TFLu_benchmark-model_mbed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'LeNet' in model_name:\n",
    "    patch_arena_size(cmsis_selections.value[0], 60)\n",
    "elif 'ResNet' in model_name:\n",
    "    patch_arena_size(cmsis_selections.value[0], 150)\n",
    "else:\n",
    "    patch_arena_size(cmsis_selections.value[0], 220)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a final summary of all the settings and the upcoming benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 126 combinations which will be benchmarked.\n"
     ]
    }
   ],
   "source": [
    "fpus = fpu_selections.value\n",
    "compiler_flags = compiler_selections.value\n",
    "tfl_model_files_selection = tfl_model_selections.value\n",
    "mbed_dirs = cmsis_selections.value\n",
    "\n",
    "target_devices = target_selections.value\n",
    "baudrate = int(baudrate_slider.value)\n",
    "\n",
    "total_combinations = len(fpus) * len(compiler_flags) * len(tfl_model_files_selection) * len(mbed_dirs)\n",
    "print(f\"We have a total of {total_combinations} combinations which will be benchmarked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mbed] Working path \"/Users/nope/ownCloud/projects/masterthesis/jupyter-workspace/ML-on-MCU_toolchain\" (program)\n",
      "[mbed] WARNING: The mbed-os tools were not found in \"/Users/nope/ownCloud/projects/masterthesis/jupyter-workspace/ML-on-MCU_toolchain\". \n",
      "       Limited information will be shown about connected targets/boards\n",
      "---\n",
      "[mbed] Detected \"NUCLEO_L496ZG\" connected to \"/Volumes/NODE_L496ZG\" and using com port \"/dev/tty.usbmodem14103\"\n"
     ]
    }
   ],
   "source": [
    "!mbed detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_port = '/dev/tty.usbmodem14103'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocketLogger v1.1.5\n",
      "\n",
      "RocketLogger Configuration:\n",
      "  Sampling rate:    64kSps\n",
      "  Data aggregation: downsampleaverage\n",
      "  Update rate:      1Hz\n",
      "  Webserver:        enabled\n",
      "  Digital inputs:   enabled\n",
      "  File format:      binary\n",
      "  File name:        /home/rocketlogger/data/init-filename_2021-04-01.rld\n",
      "  Channels:         0,2,\n",
      "  Sample limit:     no limit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#setup rocketlogger\n",
    "RL = RocketLogger('192.168.2.2', '~/.ssh/eth/id_rsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ...\n",
      "++++\n",
      "Compiler flag is -Ofast\n",
      "FPU status: 1\n",
      "\tUsing the following mbed: ./TFLu_benchmark-model_mbed\n",
      "Benchmarking: 01f_Depthwise-Conv_f-100_K-1_Q-full\n",
      "Writing 'TFLite-model/01f_Depthwise-Conv_f-100_K-1_Q-full.tflite' to './TFLu_benchmark-model_mbed'\n",
      "Writing the model was successful.\n",
      "Writing image no. 7270 to './TFLu_benchmark-model_mbed'\n",
      "Writing was successful.\n",
      "\tBuilding & flashing ...\n",
      "\tFinished building & flashing.\n",
      "\tGetting size of the binary blob ...\n",
      "\tFirst emasurmeent which will be discarded - warm up.\n",
      "'rocketlogger set -r 64k -ch 0,2 -c -f /home/rocketlogger/data/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld -d -format \"bin\" -C \"\" -s'\n",
      "RocketLogger v1.1.5\n",
      "\n",
      "RocketLogger Configuration:\n",
      "  Sampling rate:    64kSps\n",
      "  Data aggregation: downsampleaverage\n",
      "  Update rate:      1Hz\n",
      "  Webserver:        enabled\n",
      "  Digital inputs:   enabled\n",
      "  File format:      binary\n",
      "  File name:        /home/rocketlogger/data/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld\n",
      "  Channels:         0,2,\n",
      "  Sample limit:     no limit\n",
      "\n",
      "RocketLogger v1.1.5\n",
      "\tBenchmarking layers (sample of 10 images) ...\n",
      "RocketLogger v1.1.5\n",
      "RocketLogger v1.1.5\n",
      "NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_20 100% 5250KB   9.4MB/s   00:00    \n",
      "Read 1 file(s)\n",
      "filename: ./results/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld\n",
      "We have 10, not as expected 100 or 200 - Aborting.\n",
      "Distribution of the layers: Counter({7.0: 10})\n",
      "We detected a maximum of 7 layers per inference. Does this sound about right?\n",
      "\n",
      "Analyzed a total of 10 inferences.\n",
      "\n",
      "Doing some sanity checks ...\n",
      "Sum of the average layer latencies:\t0.3134140625000003\n",
      "Average inference latency:\t\t0.31355781249999987\n",
      "Sum of the average layer energies:\t0.01395970628821702\n",
      "Average inference energy:\t\t0.013965877897624473\n",
      "-------------\n",
      "\n",
      "Next ...\n",
      "Benchmarking: 01f_Depthwise-Conv_f-100_K-3_Q-full\n",
      "Writing 'TFLite-model/01f_Depthwise-Conv_f-100_K-3_Q-full.tflite' to './TFLu_benchmark-model_mbed'\n",
      "Writing the model was successful.\n",
      "Writing image no. 7270 to './TFLu_benchmark-model_mbed'\n",
      "Writing was successful.\n",
      "\tBuilding & flashing ...\n",
      "\tFinished building & flashing.\n",
      "\tGetting size of the binary blob ...\n",
      "\tFirst emasurmeent which will be discarded - warm up.\n",
      "'rocketlogger set -r 64k -ch 0,2 -c -f /home/rocketlogger/data/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld -d -format \"bin\" -C \"\" -s'\n",
      "RocketLogger v1.1.5\n",
      "\n",
      "RocketLogger Configuration:\n",
      "  Sampling rate:    64kSps\n",
      "  Data aggregation: downsampleaverage\n",
      "  Update rate:      1Hz\n",
      "  Webserver:        enabled\n",
      "  Digital inputs:   enabled\n",
      "  File format:      binary\n",
      "  File name:        /home/rocketlogger/data/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld\n",
      "  Channels:         0,2,\n",
      "  Sample limit:     no limit\n",
      "\n",
      "RocketLogger v1.1.5\n",
      "\tBenchmarking layers (sample of 10 images) ...\n",
      "RocketLogger v1.1.5\n",
      "RocketLogger v1.1.5\n",
      "NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_20 100% 9584KB   8.1MB/s   00:01    \n",
      "Read 1 file(s)\n",
      "filename: ./results/NUCLEO_L496ZG_01f_Depthwise-Conv_f-100_K-1_2021-04-01.rld\n",
      "We have 9, not as expected 100 or 200 - Aborting.\n",
      "Distribution of the layers: Counter({7.0: 9})\n",
      "We detected a maximum of 7 layers per inference. Does this sound about right?\n",
      "\n",
      "Analyzed a total of 9 inferences.\n",
      "\n",
      "Doing some sanity checks ...\n",
      "Sum of the average layer latencies:\t0.8714878472222218\n",
      "Average inference latency:\t\t0.8716371527777776\n",
      "Sum of the average layer energies:\t0.03899745824620658\n",
      "Average inference energy:\t\t0.03900385858100155\n",
      "-------------\n",
      "\n",
      "Next ...\n",
      "Benchmarking: 01f_Depthwise-Conv_f-100_K-5_Q-full\n",
      "Writing 'TFLite-model/01f_Depthwise-Conv_f-100_K-5_Q-full.tflite' to './TFLu_benchmark-model_mbed'\n",
      "Writing the model was successful.\n",
      "Writing image no. 7270 to './TFLu_benchmark-model_mbed'\n",
      "Writing was successful.\n",
      "\tBuilding & flashing ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Starting ...\\n++++\")\n",
    "\n",
    "# requires recompilation of the project\n",
    "for target_device in target_devices:\n",
    "    for compiler_flag in compiler_flags:\n",
    "        print(\"Compiler flag is\", compiler_flag)\n",
    "\n",
    "        # requires recompilation of the project\n",
    "        for fpu_status in fpus:\n",
    "            print(\"FPU status:\", fpu_status)\n",
    "\n",
    "            for mbed_dir in mbed_dirs: # cmsis-nn and none\n",
    "                print(\"\\tUsing the following mbed:\", mbed_dir)\n",
    "\n",
    "                # we loop first over the files, as we don't need to recompile the whole project\n",
    "                for tfl_model_file in tfl_model_files_selection:\n",
    "\n",
    "                    try:\n",
    "                        table_layers_summary, table_energy_summary = run_benchmark(RL, target_device, serial_port,\n",
    "                                                                                   baudrate, tfl_model_file, mbed_dir, \n",
    "                                                                                   compiler_flag, fpu_status,\n",
    "                                                                                   no_samples=10)\n",
    "\n",
    "                        table_firmware = table_firmware.append(table_layers_summary, ignore_index=True)\n",
    "                        table_energy = table_energy.append(table_energy_summary, ignore_index=True)\n",
    "                    except Exception as err:\n",
    "                        print(\"Error encountered; skipping. Errror: \",err)\n",
    "                    #print(model_information)\n",
    "                    print(\"-------------\\n\\nNext ...\")\n",
    "\n",
    "print(\"Fin.\")\n",
    "\n",
    "table_firmware.to_pickle(f\"results/F-combined_no-cmsis_{target_device[0]}_{model_name}_layer_results_{date.today()}.pkl\")\n",
    "table_firmware.to_excel(f\"results/F-combined_no-cmsis_{target_device[0]}_{model_name}_layer_results_{date.today()}.xlsx\")\n",
    "\n",
    "\n",
    "table_energy.to_pickle(f\"results/F-combined_no-cmsis_{target_device[0]}_{model_name}_energy_results_{date.today()}.pkl\")\n",
    "table_energy.to_excel(f\"results/F-combined_no-cmsis_{target_device[0]}_{model_name}_energy_results_{date.today()}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
