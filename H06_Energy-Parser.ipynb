{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Analysis\n",
    "\n",
    "This notebook analysis the `.rld` files from the RocketLogger energy measurement. It analysis the digital traces to mark the beginning and end of each inference and layer.\n",
    "The resulting Dataframe only contains the averaged result of a single layer.\n",
    "\n",
    "\n",
    "For file size reasons the original `.rld` files are not included in this repo.\n",
    "\n",
    "The results are already in `results_energy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the usage of the RocketLoggerData API see [here](https://rocketlogger.ethz.ch/python/v1.1.6/).\n",
    "\n",
    "- **DI1:** Inference Indicator\n",
    "- **DI2:** Layer toggle\n",
    "- **DI3:** Waiting for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rocketlogger.data import RocketLoggerData\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, date\n",
    "import json\n",
    "# import glob\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut data\n",
    "sample_step = 1/64000\n",
    "\n",
    "start_in_s = 0.01\n",
    "stop_in_s = -1\n",
    "\n",
    "cut_start = int(start_in_s // sample_step)\n",
    "cut_start = 0\n",
    "cut_stop = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'energy_measurements/20200805_102739_inference-energy_measurement.rld'\n",
    "\n",
    "# rld = RocketLoggerData(filename)\n",
    "# comment = rld.get_comment()\n",
    "# print(comment)\n",
    "# energy_inference_table, energy_inference_layer_table = energy_analysis(rld, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = glob.glob('energy_measurements/*.rld')\n",
    "# df = pd.DataFrame()\n",
    "# df_layers = pd.DataFrame()\n",
    "\n",
    "# df = pd.concat([df, ])\n",
    "# for file in filenames:\n",
    "#     print(\"\\n----\\nNext ...\")\n",
    "#     rld = RocketLoggerData(file)\n",
    "#     comment = rld.get_comment()\n",
    "#     ### Manually filter\n",
    "# #     if ('F4' not in comment) or ('ResNet' not in comment) or ('float32' not in comment):\n",
    "# #         continue\n",
    "# #         print(\"Skipping ...\")\n",
    "#     print(comment)\n",
    "    \n",
    "#     energy_inference_table, energy_inference_layer_table = energy_analysis(rld, file)\n",
    "#     df = pd.concat([df, energy_inference_table])\n",
    "#     df_layers = pd.concat([df_layers, energy_inference_layer_table])\n",
    "\n",
    "# df.to_excel('results_energy/A_Aggregated_energy_inference_table.xlsx')\n",
    "# df.to_pickle('results_energy/A_Aggregated_energy_inference_table.pkl')\n",
    "\n",
    "# df_layers.to_excel('results_energy/A_Aggregated_energy_inference_layer_table.xlsx')\n",
    "# df_layers.to_pickle('results_energy/A_Aggregated_energy_inference_layer_table.pkl')\n",
    "# print(\"\\nfin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_analysis(filename, model_information):\n",
    "    rld = RocketLoggerData(filename)\n",
    "\n",
    "    print(f\"filename: {filename}\")\n",
    "    rld.remove_channel('DI4')\n",
    "    rld.remove_channel('DI5')\n",
    "    rld.remove_channel('DI6')\n",
    "    \n",
    "    channels = rld.get_channel_names()\n",
    "    data = {}\n",
    "    data['time'] = rld.get_time()\n",
    "    for channel in channels:\n",
    "        data[channel] = rld.get_data(channel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    no_layers = 0\n",
    "    columns = ['time','filename', 'MCU', 'model', 'model_name', 'mbed-dir',\n",
    "               'cmsis-nn', 'compiler_optimization', 'FPU_status',\n",
    "               'model_type',\n",
    "               'weights', 'activations', 'pruned',\n",
    "               'no_correct_inferences',\n",
    "               'latency_mean', 'latency_std',\n",
    "               'voltage_mean', 'voltage_std',\n",
    "               'current_mean', 'current_std',\n",
    "               'power_mean', 'power_std',\n",
    "               'energy_mean', 'energy_std'\n",
    "              ]\n",
    "    energy_inference_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "    columns = ['time', 'filename', 'MCU', 'model', 'model_name', 'mbed-dir',\n",
    "               'cmsis-nn', 'compiler_optimization', 'FPU_status',\n",
    "               'model_type',\n",
    "               'weights', 'activations', 'pruned',\n",
    "               'no_correct_inferences',\n",
    "               'layer',\n",
    "               'layer_latency_mean', 'layer_latency_std',\n",
    "               'layer_sample_length_mean', 'layer_sample_length_std',\n",
    "               'layer_voltage_mean', 'layer_voltage_std',\n",
    "               'layer_current_mean', 'layer_current_std',\n",
    "               'layer_power_mean', 'layer_power_std',\n",
    "               'layer_energy_mean', 'layer_energy_std'\n",
    "              ]\n",
    "    energy_inference_layer_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # so here we are interested in raising and falling edges of DI1 \n",
    "    # each edge marks a beginning or either an end of a single inference\n",
    "    # [beg, end, beg, end, beg, end, ...]\n",
    "    inference_edges = np.where(data['DI1'][:-1] != data['DI1'][1:])[0]\n",
    "    no_inferences = inference_edges.shape[0] // 2\n",
    "    if no_inferences == 100 or no_inferences == 200:\n",
    "        print(f'Detected exactly 100 or 200 inferences - continuing ...')\n",
    "    else:\n",
    "        print(f'We have {no_inferences}, not as expected 100 or 200 - Aborting.')\n",
    "\n",
    "    # check how many layers\n",
    "    no_layers_arr = np.array([])\n",
    "    \n",
    "    for i, (i_beg, i_end) in enumerate(zip(inference_edges[0::2]+1, inference_edges[1::2]+1)):\n",
    "        layer_trace = data['DI2'][i_beg-10:i_end+10]\n",
    "        layer_edges = np.where(layer_trace[:-1] != layer_trace[1:])[0]\n",
    "        \n",
    "        # the total number of layers is the amount of toggles we detect - 1\n",
    "        # basically everything toggle indicates a layer except the last toggle\n",
    "        no_layers_arr= np.append(no_layers_arr, layer_edges.shape[0] - 1)\n",
    "        \n",
    "\n",
    "    #print(f\"min:{no_layers_arr.min()}\")\n",
    "    #print(f\"max:{no_layers_arr.max()}\")\n",
    "    print(f\"Distribution of the layers: {collections.Counter(no_layers_arr)}\")\n",
    "    no_layers = int(no_layers_arr.max())\n",
    "    \n",
    "    # remove all the inferences which have not the right amount of layers\n",
    "    faulty_layers_index = np.where(no_layers_arr != no_layers)[0]\n",
    "    #print(faulty_layers_index)\n",
    "    #print(inference_edges)\n",
    "    faulty_layers_index = np.concatenate([faulty_layers_index*2, (faulty_layers_index*2)+1])\n",
    "    #print(faulty_layers_index)\n",
    "    inference_edges = np.delete(inference_edges, faulty_layers_index)\n",
    "    #print(inference_edges)\n",
    "\n",
    "    # update the total number of inferences\n",
    "    no_inferences = inference_edges.shape[0] // 2\n",
    "\n",
    "\n",
    "    print(f'We detected a maximum of {no_layers} layers per inference. Does this sound about right?')\n",
    "\n",
    "    # writing all the model information\n",
    "    # parse comment of the rocketlogger file and save the information\n",
    "    print(rld.get_comment())\n",
    "    #model_information = json.loads(rld.get_comment())\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    model_information['filename'] = filename\n",
    "    model_information['no_correct_inferences'] = no_inferences\n",
    "    # some of the earlier measurements don't have the key 'model_name'\n",
    "    if not 'model_name' in model_information.keys():\n",
    "        if 'LeNet' in model_information['model']:\n",
    "            model_information['model_name'] = 'LeNet-MNIST'\n",
    "        elif 'ResNet' in model_information['model']:\n",
    "            model_information['model_name'] = '01d_ResNet20_CIFAR-10'\n",
    "\n",
    "    inference_dict = model_information\n",
    "    for _ in range(no_layers):\n",
    "        energy_inference_layer_table = energy_inference_layer_table.append(model_information, ignore_index = True)\n",
    "\n",
    "    inference_latencies= np.array([])\n",
    "    inference_voltages_mean = np.array([])\n",
    "    inference_voltages_std = np.array([])\n",
    "    inference_currents_mean = np.array([])\n",
    "    inference_currents_std = np.array([])\n",
    "    inference_powers_mean = np.array([])\n",
    "    inference_powers_std = np.array([])\n",
    "    inference_energies = np.array([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    layer_latencies = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_sample_lengths = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_voltages_mean = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_voltages_std = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_currents_mean = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_currents_std = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_powers_mean = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "    layer_powers_std = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "\n",
    "    layer_energies = np.array(no_layers *[no_inferences * [np.nan]])\n",
    "\n",
    "    # iterate over the inferences\n",
    "    # all even indices make a start, all uneven make an end\n",
    "    for i, (i_beg, i_end) in enumerate(zip(inference_edges[0::2]+1, inference_edges[1::2]+1)):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # increase the inference beginning (i_beg) by a single indice\n",
    "        # the trace now starts where the gpio is up\n",
    "        # and ends at the last indice where the gpio is up\n",
    "        time_trace = data['time'][i_beg:i_end]\n",
    "        # as we do a high side measurement our voltage is connected to the ground of the MCU\n",
    "        # we measure a negative voltage -> change sign\n",
    "        voltage_trace = -1 * data['V1'][i_beg:i_end]\n",
    "        current_trace = data['I1H'][i_beg:i_end]\n",
    "\n",
    "        inference_power_trace = np.multiply(voltage_trace.flatten(), current_trace.flatten())\n",
    "        inference_energy = np.trapz(inference_power_trace, time_trace)\n",
    "\n",
    "        # i_end already has the index were the gpio is low again\n",
    "        inference_latencies = np.append(inference_latencies, time_trace[-1] - time_trace[0])\n",
    "        inference_voltages_mean  = np.append(inference_voltages_mean , voltage_trace.mean())\n",
    "        inference_voltages_std = np.append(inference_voltages_std , voltage_trace.std())\n",
    "        inference_currents_mean = np.append(inference_currents_mean , current_trace.mean())\n",
    "        inference_currents_std = np.append(inference_currents_std , current_trace.std())\n",
    "        inference_powers_mean = np.append(inference_powers_mean , inference_power_trace.mean())\n",
    "        inference_powers_std = np.append(inference_powers_std , inference_power_trace.std())\n",
    "        inference_energies = np.append(inference_energies , inference_energy)\n",
    "\n",
    "\n",
    "        # increase the layer trace array in case the layer gpio was toggled at the same time as the inference\n",
    "        layer_trace = data['DI2'][i_beg-10:i_end+10]\n",
    "        time_trace = data['time'][i_beg-10:i_end+10]\n",
    "        voltage_trace = -1 * data['V1'][i_beg-10:i_end+10]\n",
    "        current_trace = data['I1H'][i_beg-10:i_end+10]\n",
    "\n",
    "\n",
    "        layer_edges = np.where(layer_trace[:-1] != layer_trace[1:])[0]\n",
    "\n",
    "        #print(f\"Inference #{i} is from {i_beg} to {i_end}, so a total of {i_end - i_beg}\")\n",
    "        #print(\"We do have #layers:\",layer_edges.size - 1)\n",
    "        #print(\"Layer edges\", layer_edges)\n",
    "\n",
    "\n",
    "        # so here we are interested in raising and falling edges\n",
    "        # each edge marks a beginning and simultaneously an end\n",
    "        # [beg, end/beg, end/beg, end/beg, beg/end, ..., end]\n",
    "        for j, (l_beg, l_end) in enumerate(zip(layer_edges[0:-1]+1, layer_edges[1:]+1)):\n",
    "            # j indicates the layer no.\n",
    "            # to know the type of layer we have to check the network\n",
    "            \n",
    "           # print(f\"\\tLayer #{j} from {l_beg} to {l_end}, so a total of {l_end - l_beg}\")\n",
    "            \n",
    "\n",
    "            layer_time_trace = time_trace[l_beg:l_end]\n",
    "            layer_power_trace = np.multiply(voltage_trace[l_beg:l_end].flatten(), current_trace[l_beg:l_end].flatten())\n",
    "            layer_energy = np.trapz(layer_power_trace, layer_time_trace)\n",
    "\n",
    "            # use the previous resut (first time = 0) and calculate the mean\n",
    "\n",
    "            # the calculation of the standard deviation and the updating might be wrong!\n",
    "\n",
    "            #print(f\"layer #{i}: current array {layer_latencies[i]}, new calc {time_trace[l_end] - time_trace[l_beg]}\")\n",
    "            try:\n",
    "                layer_latencies[j][i] = layer_time_trace[-1] - layer_time_trace[0]\n",
    "            except IndexError:\n",
    "                print(\"Detected a layer which is only 1 sample long. Length will be set to the length of a single sample.\")\n",
    "                layer_latencies[j][i] = 1/64000\n",
    "            layer_sample_lengths[j][i] = l_end - l_beg\n",
    "            layer_voltages_mean[j] = voltage_trace[l_beg:l_end].mean()\n",
    "            layer_voltages_std[j][i] = voltage_trace[l_beg:l_end].std()\n",
    "            layer_currents_mean[j][i] = current_trace[l_beg:l_end].mean()\n",
    "            layer_currents_std[j][i] = current_trace[l_beg:l_end].std()\n",
    "            layer_powers_mean[j][i] = layer_power_trace.mean()\n",
    "            layer_powers_std[j][i] = layer_power_trace.std()\n",
    "            layer_energies[j][i] = layer_energy\n",
    "\n",
    "    print(f\"Analyzed a total of {i+1} inferences.\")\n",
    "    # save layer data in the table\n",
    "    if no_layers > 0:\n",
    "        energy_inference_layer_table['layer'] = range(no_layers)\n",
    "        energy_inference_layer_table['layer_latency_mean'] = layer_latencies.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_latency_std'] = layer_latencies.std(axis=1)\n",
    "        energy_inference_layer_table['layer_sample_length_mean'] = layer_sample_lengths.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_sample_length_std'] = layer_sample_lengths.std(axis=1)\n",
    "        energy_inference_layer_table['layer_voltage_mean'] = layer_voltages_mean.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_voltage_std'] = layer_voltages_std.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_current_mean'] = layer_currents_mean.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_current_std'] = layer_currents_std.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_power_mean'] = layer_powers_mean.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_power_std'] = layer_powers_std.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_energy_mean'] = layer_energies.mean(axis=1)\n",
    "        energy_inference_layer_table['layer_energy_std'] = layer_energies.std(axis=1)\n",
    "\n",
    "\n",
    "#         energy_inference_layer_table.to_pickle(f\"results/\"\n",
    "#                                         f\"{model_information['MCU']}_\"\n",
    "#                                         f\"{model_information['model']}_\"\n",
    "#                                         f\"{model_information['model_type']}_\"\n",
    "#                                         f\"{model_information['cmsis-nn']}_\"\n",
    "#                                          f\"energy-layer_results_{date.today()}.pkl\")\n",
    "#         #energy_inference_layer_table.to_excel(f\"results_energy/{model_information['MCU']}_{model_information['model']}_energy-layer_results_{date.today()}.xlsx\")\n",
    "\n",
    "\n",
    "    # print(inference_latencies, \"s\")\n",
    "    # print(inference_voltages_mean, \"V\")\n",
    "    # print(inference_currents_mean,\"mA\")\n",
    "    # print(inference_powers_mean, \"W\")\n",
    "    # print(inference_energies, \"J\")\n",
    "\n",
    "\n",
    "    # save infererence data in a dict\n",
    "    inference_dict['latency_mean'] = inference_latencies.mean()\n",
    "    inference_dict['latency_std'] = inference_latencies.std()\n",
    "    inference_dict['voltage_mean'] = inference_voltages_mean.mean()\n",
    "    inference_dict['voltage_std'] = inference_voltages_std.mean()\n",
    "    inference_dict['current_mean'] = inference_currents_mean.mean()\n",
    "    inference_dict['current_std'] = inference_currents_std.mean()\n",
    "    inference_dict['power_mean'] = inference_powers_mean.mean()\n",
    "    inference_dict['power_std'] = inference_powers_std.mean()\n",
    "    inference_dict['energy_mean'] = inference_energies.mean()\n",
    "    inference_dict['energy_std'] = inference_energies.std()\n",
    "\n",
    "    # add dict to table\n",
    "    energy_inference_table = energy_inference_table.append(inference_dict, ignore_index=True)\n",
    "\n",
    "#     energy_inference_table.to_pickle(f\"results/\"\n",
    "#                                     f\"{model_information['MCU']}_\"\n",
    "#                                     f\"{model_information['model']}_\"\n",
    "#                                     f\"{model_information['model_type']}_\"\n",
    "#                                     f\"{model_information['cmsis-nn']}_\"\n",
    "#                                      f\"energy_results_{date.today()}.pkl\")\n",
    "\n",
    "    #energy_inference_table.to_excel(f\"results_energy/{model_information['MCU']}_{model_information['model']}_energy_results_{date.today()}.xlsx\")\n",
    "\n",
    "\n",
    "    print(\"\\nDoing some sanity checks ...\")\n",
    "    print(f\"Sum of the average layer latencies:\\t{energy_inference_layer_table['layer_latency_mean'].sum()}\")\n",
    "    print(f\"Average inference latency:\\t\\t{energy_inference_table['latency_mean'][0]}\")\n",
    "\n",
    "    print(f\"Sum of the average layer energies:\\t{energy_inference_layer_table['layer_energy_mean'].sum()}\")\n",
    "    print(f\"Average inference energy:\\t\\t{energy_inference_table['energy_mean'][0]}\")\n",
    "    \n",
    "    return energy_inference_table, energy_inference_layer_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported helper functions from H06_Energy-Parser.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"Imported helper functions from H06_Energy-Parser.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
