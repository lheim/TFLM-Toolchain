{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "\n",
    "Before converting the network we could use [pruning](https://www.tensorflow.org/model_optimization/guide/pruning).\n",
    "\n",
    "\n",
    "Documentation: [tfmot.sparsity.keras.prune_low_magnitude](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/prune_low_magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:193: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_4 (None, 30, 30, 6)         116       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_average_ (None, 15, 15, 6)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_5 (None, 13, 13, 16)        1746      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_average_ (None, 6, 6, 16)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 576)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_6  (None, 120)               138362    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_7  (None, 84)                20246     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_8  (None, 10)                1692      \n",
      "=================================================================\n",
      "Total params: 162,165\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 80,971\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1\n",
    "\n",
    "num_images = x_train_normalized.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.5,\n",
    "                                                            final_sparsity=0.8,\n",
    "                                                            begin_step=0,\n",
    "                                                            end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(tf_model, **pruning_params)\n",
    "\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                         loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 7s 18ms/step - loss: 1.5071 - accuracy: 0.9629 - val_loss: 1.5362 - val_accuracy: 0.9548\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 1.4986 - accuracy: 0.9730 - val_loss: 1.4813 - val_accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162fafca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "logdir = './logs'\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "#  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "model_for_pruning.fit(x_train_normalized, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0628 16:06:07.765544 123145418182656 plugin_event_accumulator.py:332] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0628 16:06:07.770737 123145418182656 plugin_event_accumulator.py:332] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0628 16:06:07.776291 123145418182656 plugin_event_accumulator.py:332] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.2.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "!tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the pruned model\n",
    "\n",
    "Both `tfmot.sparsity.keras.strip_pruning` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression benefits of pruning.\n",
    "\n",
    "> Once a model has been pruned to required sparsity, this method can be used to restore the original model with the sparse weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: ./keras-model/LeNet-MNIST_pruned.h5\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "tf_model_pruned_file = './keras-model/LeNet-MNIST_pruned.h5'\n",
    "\n",
    "tf.keras.models.save_model(model_for_export, tf_model_pruned_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', tf_model_pruned_file)\n",
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\t\t 0.9879000186920166\n",
      "Test accuracy (pruned):\t 0.98089998960495\n",
      "Test loss:\t\t 0.04126233980059624\n",
      "Test loss (pruned):\t 1.4850536584854126\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "score = model_for_pruning.evaluate(x=x_test_normalized, y=y_test, verbose=0)\n",
    "\n",
    "tf_model_pruned_loss = score[0]\n",
    "tf_model_pruned_accuracy = score[1]\n",
    "\n",
    "print('Test accuracy:\\t\\t', tf_model_accuracy)\n",
    "print('Test accuracy (pruned):\\t', tf_model_pruned_accuracy)\n",
    "print('Test loss:\\t\\t', tf_model_loss)\n",
    "print('Test loss (pruned):\\t', tf_model_pruned_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test squared loss (manually):\t 0.0029721695\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "prediction = model_for_pruning.predict(x_test_normalized)\n",
    "prediction_delta = np.mean((prediction - y_test) ** 2)\n",
    "\n",
    "print('Test squared loss (manually):\\t', prediction_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test squared loss:\t 0.002972168\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "squared_loss = loss_fn(y_test, prediction)\n",
    "print('Test squared loss:\\t', squared_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should match our previous loss from the `model.evaluate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test crossentropy loss:\t 0.062741384\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "crossentropy_loss = loss_fn(y_test, prediction)\n",
    "print('Test crossentropy loss:\\t', crossentropy_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  zipped_file = './keras-model/pruned.zip'\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of baseline Keras model:\t 1021632.00 bytes\n",
      "Size of pruned Keras model:\t 349032.00 bytes\n",
      "\n",
      "gzipped:\n",
      "Size of gzipped baseline Keras model:\t 914806.00 bytes\n",
      "Size of gzipped pruned Keras model:\t 99547.00 bytes\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "print(\"Size of baseline Keras model:\\t %.2f bytes\" % os.path.getsize(tf_model_file))\n",
    "print(\"Size of pruned Keras model:\\t %.2f bytes\" % os.path.getsize(tf_model_pruned_file))\n",
    "print(\"\\ngzipped:\")\n",
    "print(\"Size of gzipped baseline Keras model:\\t %.2f bytes\" % (get_gzipped_model_size(tf_model_file)))\n",
    "print(\"Size of gzipped pruned Keras model:\\t %.2f bytes\" % (get_gzipped_model_size(tf_model_pruned_file)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md#hardware-specific_optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model_pruned = tf.keras.models.load_model('./keras-model/LeNet-MNIST_pruned.h5')\n",
    "tf_model_pruned.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore sparisty and check zeros for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_4_4/kernel:0 -- \tTotal:54, Zeros: 0.00%\n",
      "conv2d_4_4/bias:0 -- \tTotal:6, Zeros: 0.00%\n",
      "conv2d_5_4/kernel:0 -- \tTotal:864, Zeros: 0.00%\n",
      "conv2d_5_4/bias:0 -- \tTotal:16, Zeros: 0.00%\n",
      "dense_6_4/kernel:0 -- \tTotal:69120, Zeros: 0.00%\n",
      "dense_6_4/bias:0 -- \tTotal:120, Zeros: 0.00%\n",
      "dense_7_4/kernel:0 -- \tTotal:10080, Zeros: 0.00%\n",
      "dense_7_4/bias:0 -- \tTotal:84, Zeros: 0.00%\n",
      "dense_8_4/kernel:0 -- \tTotal:840, Zeros: 0.00%\n",
      "dense_8_4/bias:0 -- \tTotal:10, Zeros: 0.00%\n",
      "---\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "conv2d_4_5/kernel:0 -- \tTotal:54, Zeros: 79.63%\n",
      "conv2d_4_5/bias:0 -- \tTotal:6, Zeros: 0.00%\n",
      "conv2d_5_5/kernel:0 -- \tTotal:864, Zeros: 79.98%\n",
      "conv2d_5_5/bias:0 -- \tTotal:16, Zeros: 0.00%\n",
      "dense_6_5/kernel:0 -- \tTotal:69120, Zeros: 80.00%\n",
      "dense_6_5/bias:0 -- \tTotal:120, Zeros: 0.00%\n",
      "dense_7_5/kernel:0 -- \tTotal:10080, Zeros: 80.00%\n",
      "dense_7_5/bias:0 -- \tTotal:84, Zeros: 0.00%\n",
      "dense_8_5/kernel:0 -- \tTotal:840, Zeros: 80.00%\n",
      "dense_8_5/bias:0 -- \tTotal:10, Zeros: 0.00%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "for file in [tf_model_file, tf_model_pruned_file]:\n",
    "    model = load_model(file)\n",
    "    import numpy as np\n",
    "\n",
    "    for i, w in enumerate(model.get_weights()):\n",
    "        print(\n",
    "            \"{} -- \\tTotal:{}, Zeros: {:.2f}%\".format(\n",
    "                model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
    "            )\n",
    "        )\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
