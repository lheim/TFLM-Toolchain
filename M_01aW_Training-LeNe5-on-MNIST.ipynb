{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet5 on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported helper functions from 00_README.ipynb\n",
      "Imported all modules.\n",
      "\tTensorflow Version:  2.2.0\n",
      "\tNumpy Version:  1.19.0\n",
      "\tPandas Version:  1.0.5\n"
     ]
    }
   ],
   "source": [
    "%run '00_README.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LeNet 5\n",
    "\n",
    "![LeNet5 Architecutr](https://miro.medium.com/max/1400/0*H9_eGAtkQXJXtkoK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data x shape: (60000, 28, 28, 1)\n",
      "training data y shape: (60000,)\n",
      "training data y shape with categories: (60000, 10)\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "print(\"training data x shape:\", x_train.shape)\n",
    "print(\"training data y shape:\", y_train.shape)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"training data y shape with categories:\", y_train.shape)\n",
    "\n",
    "plt.imshow(x_train[2917].squeeze(), cmap=plt.cm.gray_r)\n",
    "print(y_train[2917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dc09ec003f4bcf9aa81f54c25f90d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "sns.set(context='paper', style=\"ticks\", color_codes=True, font='Times New Roman', font_scale=1, rc={\"axes.grid\": True })\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    #plt.style.use(['dark_background'])\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i].squeeze(), cmap=plt.cm.gray_r)\n",
    "    #plt.xlabel(y_train[i][0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('MNIST_examples.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "#### Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (60000, 28, 28, 1)\n",
      "test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_normalized = x_train / 255\n",
    "x_test_normalized = x_test / 255\n",
    "\n",
    "print(\"training data shape:\", x_train_normalized.shape)\n",
    "print(\"test data shape:\", x_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet accepts 32x32, mnist is 28x28. Adding zero pads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (60000, 32, 32, 1)\n",
      "test data shape: (10000, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x158d14610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero padding accross the 'images', 2,2 accross the x-axis, 2,2 accross the y-axis\n",
    "x_train_normalized = np.pad(x_train_normalized, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_test_normalized = np.pad(x_test_normalized, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "print(\"training data shape:\", x_train_normalized.shape)\n",
    "print(\"test data shape:\", x_test_normalized.shape)\n",
    "\n",
    "plt.imshow(x_train[2917].squeeze(), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input and output length for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = x_test_normalized[1].flatten().shape[0]\n",
    "OUTPUT_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "*this can be skipped if the model file is already available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=7, kernel_size=(5, 5), activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "    \n",
    "    model.add(layers.Conv2D(filters=17, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(layers.AveragePooling2D())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(units=121, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(units=81, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                 loss=\"categorical_crossentropy\",\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_features, train_label, epochs,\n",
    "               batch_size=None, validation_split=0.1):\n",
    "    \n",
    "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                       epochs=epochs, shuffle=True,\n",
    "                       validation_split=validation_split)\n",
    "    \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    \n",
    "    return epochs, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the previous functions to build & train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:  (60000, 32, 32, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 7)         182       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 14, 14, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 17)        2992      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 5, 5, 17)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 425)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 121)               51546     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 81)                9882      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                820       \n",
      "=================================================================\n",
      "Total params: 65,422\n",
      "Trainable params: 65,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 7s 512ms/step - loss: 1.5563 - accuracy: 0.5559 - val_loss: 0.5970 - val_accuracy: 0.8198\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 7s 506ms/step - loss: 0.5628 - accuracy: 0.8286 - val_loss: 0.3354 - val_accuracy: 0.9037\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 7s 504ms/step - loss: 0.3684 - accuracy: 0.8923 - val_loss: 0.2531 - val_accuracy: 0.9250\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 7s 514ms/step - loss: 0.2867 - accuracy: 0.9148 - val_loss: 0.1991 - val_accuracy: 0.9410\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 8s 568ms/step - loss: 0.2321 - accuracy: 0.9299 - val_loss: 0.1665 - val_accuracy: 0.9523\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 9s 619ms/step - loss: 0.1918 - accuracy: 0.9424 - val_loss: 0.1355 - val_accuracy: 0.9623\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 8s 576ms/step - loss: 0.1593 - accuracy: 0.9519 - val_loss: 0.1154 - val_accuracy: 0.9677\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 8s 548ms/step - loss: 0.1339 - accuracy: 0.9594 - val_loss: 0.0997 - val_accuracy: 0.9730\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 8s 545ms/step - loss: 0.1137 - accuracy: 0.9653 - val_loss: 0.0874 - val_accuracy: 0.9758\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 8s 551ms/step - loss: 0.0997 - accuracy: 0.9695 - val_loss: 0.0861 - val_accuracy: 0.9762\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 8s 574ms/step - loss: 0.0883 - accuracy: 0.9731 - val_loss: 0.0787 - val_accuracy: 0.9758\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 8s 540ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.0734 - val_accuracy: 0.9802\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 8s 593ms/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 0.0689 - val_accuracy: 0.9810\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.0679 - val_accuracy: 0.9797\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 8s 551ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.0624 - val_accuracy: 0.9820\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 8s 589ms/step - loss: 0.0575 - accuracy: 0.9827 - val_loss: 0.0585 - val_accuracy: 0.9828\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 10s 699ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0595 - val_accuracy: 0.9832\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 8s 569ms/step - loss: 0.0569 - accuracy: 0.9823 - val_loss: 0.0558 - val_accuracy: 0.9842\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 7s 500ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.0569 - val_accuracy: 0.9845\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 7s 510ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.0538 - val_accuracy: 0.9860\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 7s 505ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0569 - val_accuracy: 0.9832\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 9s 613ms/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.0542 - val_accuracy: 0.9853\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 8s 585ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.0546 - val_accuracy: 0.9850\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 9s 615ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.0508 - val_accuracy: 0.9863\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 7s 535ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 8s 565ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0490 - val_accuracy: 0.9860\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 8s 544ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0478 - val_accuracy: 0.9863\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 8s 547ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.0472 - val_accuracy: 0.9872\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 8s 558ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0466 - val_accuracy: 0.9867\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 7s 524ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.0468 - val_accuracy: 0.9877\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 7s 532ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.0446 - val_accuracy: 0.9880\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 7s 536ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0478 - val_accuracy: 0.9882\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 8s 545ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0467 - val_accuracy: 0.9873\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 8s 565ms/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.0450 - val_accuracy: 0.9887\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 7s 517ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 0.0490 - val_accuracy: 0.9875\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 7s 496ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0462 - val_accuracy: 0.9875\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 7s 501ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0498 - val_accuracy: 0.9870\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 7s 497ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0464 - val_accuracy: 0.9877\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 8s 548ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0435 - val_accuracy: 0.9895\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 7s 525ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0504 - val_accuracy: 0.9867\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 7s 515ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0457 - val_accuracy: 0.9885\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 8s 545ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 8s 542ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 7s 520ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0468 - val_accuracy: 0.9885\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 9s 669ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.0441 - val_accuracy: 0.9887\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 8s 575ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0509 - val_accuracy: 0.9882\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 8s 540ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.0483 - val_accuracy: 0.9887\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 8s 584ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 8s 540ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.0488 - val_accuracy: 0.9887\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 7s 511ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0530 - val_accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ddef68b73049a795fc5dd126b0da0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14d81e370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4000\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "validation_split = 0.1\n",
    "\n",
    "\n",
    "\n",
    "print(\"shape of x_train: \", x_train_normalized.shape)\n",
    "\n",
    "tf_model = create_model(learning_rate)\n",
    "\n",
    "epochs, hist = train_model(tf_model, x_train_normalized, y_train,\n",
    "                          epochs, batch_size, validation_split)\n",
    "\n",
    "\n",
    "metrics_to_plot = ['accuracy']\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    x = hist[metric]\n",
    "    plt.plot(epochs[1:], x[1:], label=metric)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save('./keras-model/01aW_LeNet-MNIST.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "*continue here if you want to load a pretrained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 61,182\n",
      "Trainable params: 61,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model_file = './keras-model/01a_Orginial-LeNet-MNIST.h5'\n",
    "tf_model = tf.keras.models.load_model(tf_model_file)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
