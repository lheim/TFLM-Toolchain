{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet20 on CIFAR-10\n",
    "\n",
    "Based on https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_06_3_resnet.ipynb\n",
    "\n",
    "*the model was trained in google colab with `batch=32` and no pixeal mean used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported helper functions from 00_README.ipynb\n",
      "Imported all modules.\n",
      "\tTensorflow Version:  2.2.0\n",
      "\tNumpy Version:  1.19.0\n",
      "\tPandas Version:  1.0.5\n"
     ]
    }
   ],
   "source": [
    "%run '00_README.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU for training with Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VD5aH6SvFkpO"
   },
   "source": [
    "### Getting CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3597,
     "status": "ok",
     "timestamp": 1595068346840,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "O4Wq-vscFkpQ",
    "outputId": "21ab878a-ed32-4e4e-ba3e-e30220bfd66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data x shape: (50000, 32, 32, 3)\n",
      "training data y shape: (50000, 1)\n",
      "[7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(\"training data x shape:\", x_train.shape)\n",
    "print(\"training data y shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "plt.imshow(x_train[321].squeeze())\n",
    "print(y_train[321])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbJsNqvKFkpV"
   },
   "source": [
    "#### Set input and output length globals for later (macros for mbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3243,
     "status": "ok",
     "timestamp": 1595068346841,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "1KterOpKFkpW"
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH = x_test[1].flatten().shape[0]\n",
    "OUTPUT_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqpLBFSYFkpb"
   },
   "source": [
    "### Exploring the data\n",
    "#### Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1595068347652,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "yYTfVdUaFkpc",
    "outputId": "4010285e-f6b9-4536-908c-56e358d117c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (50000, 32, 32, 3)\n",
      "test data shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train_normalized = x_train / 255\n",
    "x_test_normalized = x_test / 255\n",
    "\n",
    "print(\"training data shape:\", x_train_normalized.shape)\n",
    "print(\"test data shape:\", x_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6279,
     "status": "ok",
     "timestamp": 1595068350841,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "DmF-6eiMFkph",
    "outputId": "e316acc7-e5d1-46b5-b2ee-5e0151e2366a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cea88bd93949fbb6101a7ebb767c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib widget\n",
    "\n",
    "sns.set(context='paper', style=\"ticks\", color_codes=True, font='Times New Roman', font_scale=1, rc={\"axes.grid\": True })\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    #plt.style.use(['dark_background'])\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_normalized[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i][0]], fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('CIFAR-10_examples.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT1uEG3IFkps"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4733,
     "status": "ok",
     "timestamp": 1595068350843,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "iTXPFyJ9Fkps"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 32  # orig paper trained all networks with batch_size=128\n",
    "EPOCHS = 1 # 200\n",
    "\n",
    "USE_AUGMENTATION = False\n",
    "# Subtracting pixel mean improves accuracy\n",
    "SUBTRACT_PIXEL_MEAN = False\n",
    "\n",
    "NUM_CLASSES = np.unique(y_train).shape[0] # 10\n",
    "COLORS = x_train.shape[3]\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "DEPTH = COLORS * 6 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data y shape: (50000, 1)\n",
      "training data y shape with categories: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data y shape:\", y_train.shape)\n",
    "\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"training data y shape with categories:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4291,
     "status": "ok",
     "timestamp": 1595068350843,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "TFVwgR9YFkpw"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vtzAzouFkp1"
   },
   "source": [
    "The following code implements a ResNet block. This includes two convolutional layers with a skip connection. Both V1 and V2 of ResNet make use of this type of layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2717,
     "status": "ok",
     "timestamp": 1595068350844,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "SC0N-MpvFkp3"
   },
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = layers.Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = layers.Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = layers.Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msrfSIv3Fkp6"
   },
   "source": [
    "ResNet V1\n",
    "- K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385,2015.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1651,
     "status": "ok",
     "timestamp": 1595068350846,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "2GF7Xv4GFkp7"
   },
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10, kernel_size=3):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature \n",
    "    map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of \n",
    "    filters is\n",
    "    doubled. Within each stage, the layers have the same number \n",
    "    filters and the same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs, kernel_size=kernel_size)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            # first layer but not first stack\n",
    "            if stack > 0 and res_block == 0:  \n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides, kernel_size=kernel_size)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None, kernel_size=kernel_size)\n",
    "            # first layer but not first stack\n",
    "            if stack > 0 and res_block == 0:  \n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tf.keras.layers.add([x, y])\n",
    "            x = layers.Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = layers.AveragePooling2D(pool_size=8)(x)\n",
    "    y = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    \n",
    "    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2480,
     "status": "ok",
     "timestamp": 1595068354680,
     "user": {
      "displayName": "Lennart Heim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaJQRJ3LPPRMNb_g7TGeceAwnzl6x2-3hVgmPAxA=s64",
      "userId": "14508537999212299715"
     },
     "user_tz": -120
    },
    "id": "0oA35UOBFkqE",
    "outputId": "2023f848-a86e-4184-8701-ac6e61813e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 32, 32, 16)   64          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 32, 32, 16)   64          conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 32, 32, 16)   0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 32, 32, 16)   272         activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 32, 32, 16)   64          conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 32, 32, 16)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 32, 32, 16)   272         activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 32, 32, 16)   64          conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 32, 32, 16)   0           activation_133[0][0]             \n",
      "                                                                 batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 32, 32, 16)   0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 32, 32, 16)   272         activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 32, 32, 16)   64          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 32, 32, 16)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 32, 32, 16)   272         activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 32, 32, 16)   64          conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 32, 32, 16)   0           activation_135[0][0]             \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 32, 32, 16)   0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 32, 32, 16)   272         activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 32, 32, 16)   64          conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 32, 32, 16)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 32, 32, 16)   272         activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 32, 32, 16)   64          conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 32, 32, 16)   0           activation_137[0][0]             \n",
      "                                                                 batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 32, 32, 16)   0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 16, 16, 32)   544         activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 16, 16, 32)   128         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 16, 16, 32)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 16, 16, 32)   1056        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 16, 16, 32)   544         activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 16, 16, 32)   128         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 16, 16, 32)   0           conv2d_156[0][0]                 \n",
      "                                                                 batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 16, 16, 32)   0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 32)   1056        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 16, 16, 32)   128         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 16, 16, 32)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 32)   1056        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 16, 16, 32)   128         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 16, 16, 32)   0           activation_141[0][0]             \n",
      "                                                                 batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 16, 16, 32)   0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 16, 16, 32)   1056        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 16, 16, 32)   128         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 16, 16, 32)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 16, 16, 32)   1056        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 16, 16, 32)   128         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 16, 16, 32)   0           activation_143[0][0]             \n",
      "                                                                 batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 16, 16, 32)   0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 8, 8, 64)     2112        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 8, 8, 64)     256         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 8, 8, 64)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 64)     4160        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 64)     2112        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, 8, 64)     256         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 8, 8, 64)     0           conv2d_163[0][0]                 \n",
      "                                                                 batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 8, 8, 64)     0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 64)     4160        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 64)     256         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 8, 8, 64)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 64)     4160        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 8, 8, 64)     256         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 8, 8, 64)     0           activation_147[0][0]             \n",
      "                                                                 batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 8, 8, 64)     0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 64)     4160        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 8, 8, 64)     256         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 8, 8, 64)     0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 64)     4160        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 8, 8, 64)     256         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 8, 8, 64)     0           activation_149[0][0]             \n",
      "                                                                 batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 8, 8, 64)     0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 1, 1, 64)     0           activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 64)           0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           650         flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 36,490\n",
      "Trainable params: 35,114\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 2.1482 - accuracy: 0.2635 - val_loss: 2.0794 - val_accuracy: 0.2938 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 32, 32, 16)   208         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 32, 32, 16)   64          conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 32, 32, 16)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 32, 32, 16)   1040        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 32, 32, 16)   64          conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 32, 32, 16)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 32, 32, 16)   1040        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 32, 32, 16)   64          conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 32, 32, 16)   0           activation_152[0][0]             \n",
      "                                                                 batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 32, 32, 16)   0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 32, 32, 16)   1040        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 32, 32, 16)   64          conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 32, 32, 16)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 32, 32, 16)   1040        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 32, 32, 16)   64          conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 32, 32, 16)   0           activation_154[0][0]             \n",
      "                                                                 batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 32, 32, 16)   0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 32, 32, 16)   1040        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 32, 32, 16)   64          conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 32, 32, 16)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 32, 32, 16)   1040        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 32, 32, 16)   64          conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 32, 32, 16)   0           activation_156[0][0]             \n",
      "                                                                 batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 32, 32, 16)   0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 16, 16, 32)   2080        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 16, 32)   128         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 16, 32)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 16, 16, 32)   4128        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 16, 16, 32)   544         activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 16, 16, 32)   128         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 16, 16, 32)   0           conv2d_177[0][0]                 \n",
      "                                                                 batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 16, 16, 32)   0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 16, 16, 32)   4128        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 16, 16, 32)   128         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 16, 16, 32)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 16, 16, 32)   4128        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 16, 16, 32)   128         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 16, 16, 32)   0           activation_160[0][0]             \n",
      "                                                                 batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 16, 16, 32)   0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 16, 16, 32)   4128        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 16, 16, 32)   128         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 16, 16, 32)   0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 16, 16, 32)   4128        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 16, 16, 32)   128         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 16, 16, 32)   0           activation_162[0][0]             \n",
      "                                                                 batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 16, 16, 32)   0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 64)     8256        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 64)     256         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 64)     0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 64)     16448       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 64)     2112        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 64)     256         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 8, 8, 64)     0           conv2d_184[0][0]                 \n",
      "                                                                 batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 64)     0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 64)     16448       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 64)     256         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 64)     0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 64)     16448       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 64)     256         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 8, 8, 64)     0           activation_166[0][0]             \n",
      "                                                                 batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 64)     0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 64)     16448       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 64)     256         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 64)     0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 64)     16448       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 64)     256         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 8, 8, 64)     0           activation_168[0][0]             \n",
      "                                                                 batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 64)     0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 64)     0           activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 64)           0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           650         flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 125,722\n",
      "Trainable params: 124,346\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 196s 125ms/step - loss: 1.5703 - accuracy: 0.4834 - val_loss: 1.3413 - val_accuracy: 0.5709 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 32, 16)   448         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 32, 32, 16)   64          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 32, 32, 16)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 32, 16)   2320        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 32, 32, 16)   64          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 32, 32, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 32, 32, 16)   2320        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 32, 32, 16)   64          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 32, 32, 16)   0           activation_171[0][0]             \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 32, 32, 16)   0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 32, 32, 16)   2320        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 32, 32, 16)   64          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 32, 32, 16)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 16)   2320        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 32, 32, 16)   64          conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 32, 32, 16)   0           activation_173[0][0]             \n",
      "                                                                 batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 32, 32, 16)   0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 16)   2320        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 32, 32, 16)   64          conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 32, 32, 16)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 16)   2320        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 32, 32, 16)   64          conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 32, 32, 16)   0           activation_175[0][0]             \n",
      "                                                                 batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 32, 32, 16)   0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 32)   4640        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 16, 16, 32)   128         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 16, 16, 32)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 32)   9248        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 32)   544         activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 16, 16, 32)   128         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 16, 16, 32)   0           conv2d_198[0][0]                 \n",
      "                                                                 batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 16, 16, 32)   0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   9248        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 16, 16, 32)   128         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 16, 16, 32)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 32)   9248        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 16, 16, 32)   128         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 16, 16, 32)   0           activation_179[0][0]             \n",
      "                                                                 batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 16, 16, 32)   0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 32)   9248        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 16, 16, 32)   128         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 16, 16, 32)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 32)   9248        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 16, 16, 32)   128         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 16, 16, 32)   0           activation_181[0][0]             \n",
      "                                                                 batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 16, 16, 32)   0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 64)     18496       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 64)     256         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 64)     0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 64)     36928       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 64)     2112        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 64)     256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 8, 8, 64)     0           conv2d_205[0][0]                 \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 64)     0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 64)     36928       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 64)     256         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 64)     0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 64)     36928       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 64)     256         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 8, 8, 64)     0           activation_185[0][0]             \n",
      "                                                                 batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 64)     0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 64)     36928       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 64)     256         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 64)     0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 64)     36928       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 64)     256         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 8, 8, 64)     0           activation_187[0][0]             \n",
      "                                                                 batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 64)     0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 64)     0           activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 64)           0           average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           650         flatten_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 313s 200ms/step - loss: 1.5268 - accuracy: 0.5081 - val_loss: 1.3424 - val_accuracy: 0.5748 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 16)   784         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 32, 32, 16)   64          conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 32, 32, 16)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 16)   4112        activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 32, 32, 16)   64          conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 32, 32, 16)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 16)   4112        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 32, 32, 16)   64          conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 32, 32, 16)   0           activation_190[0][0]             \n",
      "                                                                 batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 32, 32, 16)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 16)   4112        activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 32, 32, 16)   64          conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 32, 32, 16)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 16)   4112        activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 32, 32, 16)   64          conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 32, 32, 16)   0           activation_192[0][0]             \n",
      "                                                                 batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 32, 32, 16)   0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 16)   4112        activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 32, 32, 16)   64          conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 32, 32, 16)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 16)   4112        activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 32, 32, 16)   64          conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 32, 32, 16)   0           activation_194[0][0]             \n",
      "                                                                 batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 32, 32, 16)   0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 16, 16, 32)   8224        activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 32)   128         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 32)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 16, 16, 32)   16416       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 16, 16, 32)   544         activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 32)   128         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 16, 16, 32)   0           conv2d_219[0][0]                 \n",
      "                                                                 batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 32)   0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 16, 16, 32)   16416       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   128         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 16, 16, 32)   16416       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 32)   128         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 16, 16, 32)   0           activation_198[0][0]             \n",
      "                                                                 batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 32)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 16, 16, 32)   16416       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 32)   128         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 32)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 16, 16, 32)   16416       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 32)   128         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 16, 16, 32)   0           activation_200[0][0]             \n",
      "                                                                 batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 32)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 8, 8, 64)     32832       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 64)     256         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 8, 8, 64)     0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 8, 8, 64)     65600       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 8, 8, 64)     2112        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 64)     256         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 8, 8, 64)     0           conv2d_226[0][0]                 \n",
      "                                                                 batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 8, 8, 64)     0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 8, 8, 64)     65600       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 8, 8, 64)     256         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 8, 8, 64)     0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 8, 8, 64)     65600       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 8, 8, 64)     256         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 8, 8, 64)     0           activation_204[0][0]             \n",
      "                                                                 batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 8, 8, 64)     0           add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 8, 8, 64)     65600       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 8, 8, 64)     256         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 8, 8, 64)     0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 8, 8, 64)     65600       activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 8, 8, 64)     256         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 8, 8, 64)     0           activation_206[0][0]             \n",
      "                                                                 batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 8, 8, 64)     0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 64)     0           activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           650         flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 482,650\n",
      "Trainable params: 481,274\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 453s 290ms/step - loss: 1.5214 - accuracy: 0.5068 - val_loss: 1.4845 - val_accuracy: 0.5461 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 16)   1216        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 16)   64          conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 16)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 16)   6416        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 16)   64          conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 16)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 32, 32, 16)   6416        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 16)   64          conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 32, 32, 16)   0           activation_209[0][0]             \n",
      "                                                                 batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 16)   0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 32, 32, 16)   6416        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 16)   64          conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 16)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 32, 32, 16)   6416        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 16)   64          conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 32, 32, 16)   0           activation_211[0][0]             \n",
      "                                                                 batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 16)   0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 32, 32, 16)   6416        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 16)   64          conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 16)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 32, 32, 16)   6416        activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 32, 32, 16)   64          conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 32, 32, 16)   0           activation_213[0][0]             \n",
      "                                                                 batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 32, 32, 16)   0           add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 32)   12832       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 32)   128         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 32)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 32)   25632       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 16, 16, 32)   544         activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 16, 16, 32)   128         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 16, 16, 32)   0           conv2d_240[0][0]                 \n",
      "                                                                 batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 16, 16, 32)   0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 16, 16, 32)   25632       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 16, 16, 32)   128         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 16, 16, 32)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 16, 16, 32)   25632       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 16, 16, 32)   128         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 16, 16, 32)   0           activation_217[0][0]             \n",
      "                                                                 batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 16, 16, 32)   0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 16, 16, 32)   25632       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 16, 16, 32)   128         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 16, 16, 32)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 16, 16, 32)   25632       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 16, 16, 32)   128         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 16, 16, 32)   0           activation_219[0][0]             \n",
      "                                                                 batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 16, 16, 32)   0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 8, 8, 64)     51264       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 8, 8, 64)     256         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 8, 8, 64)     0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 8, 8, 64)     102464      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 8, 8, 64)     2112        activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 8, 8, 64)     256         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 8, 8, 64)     0           conv2d_247[0][0]                 \n",
      "                                                                 batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 8, 8, 64)     0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 8, 8, 64)     102464      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 8, 8, 64)     256         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 8, 8, 64)     0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 8, 8, 64)     102464      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 8, 8, 64)     256         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 8, 8, 64)     0           activation_223[0][0]             \n",
      "                                                                 batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 8, 8, 64)     0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 8, 8, 64)     102464      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 8, 8, 64)     256         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 8, 8, 64)     0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 8, 8, 64)     102464      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 8, 8, 64)     256         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 8, 8, 64)     0           activation_225[0][0]             \n",
      "                                                                 batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 8, 8, 64)     0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 1, 1, 64)     0           activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           650         flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 750,346\n",
      "Trainable params: 748,970\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 558s 357ms/step - loss: 1.5141 - accuracy: 0.5099 - val_loss: 1.4633 - val_accuracy: 0.5504 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 32, 32, 16)   1744        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 16)   64          conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 16)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 32, 32, 16)   9232        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 16)   64          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 16)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 32, 32, 16)   9232        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 16)   64          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 32, 32, 16)   0           activation_228[0][0]             \n",
      "                                                                 batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 16)   0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 32, 32, 16)   9232        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 16)   64          conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 16)   0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 32, 32, 16)   9232        activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 32, 32, 16)   64          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 32, 32, 16)   0           activation_230[0][0]             \n",
      "                                                                 batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 32, 32, 16)   0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 32, 32, 16)   9232        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 32, 32, 16)   64          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 32, 32, 16)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 32, 32, 16)   9232        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 32, 32, 16)   64          conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 32, 32, 16)   0           activation_232[0][0]             \n",
      "                                                                 batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 32, 32, 16)   0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 16, 16, 32)   18464       activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 16, 16, 32)   128         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 16, 16, 32)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 16, 16, 32)   36896       activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 32)   544         activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 16, 16, 32)   128         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 16, 16, 32)   0           conv2d_261[0][0]                 \n",
      "                                                                 batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 16, 16, 32)   0           add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 32)   36896       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 16, 16, 32)   128         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 16, 16, 32)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 32)   36896       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 16, 16, 32)   128         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 16, 16, 32)   0           activation_236[0][0]             \n",
      "                                                                 batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 16, 16, 32)   0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 32)   36896       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 16, 16, 32)   128         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 16, 16, 32)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 32)   36896       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 16, 16, 32)   128         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 16, 16, 32)   0           activation_238[0][0]             \n",
      "                                                                 batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 16, 16, 32)   0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 8, 8, 64)     73792       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 8, 8, 64)     256         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 8, 8, 64)     0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 64)     147520      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 64)     2112        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 8, 8, 64)     256         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 8, 8, 64)     0           conv2d_268[0][0]                 \n",
      "                                                                 batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 8, 8, 64)     0           add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 64)     147520      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 8, 8, 64)     256         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 8, 8, 64)     0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 64)     147520      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 8, 8, 64)     256         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 8, 8, 64)     0           activation_242[0][0]             \n",
      "                                                                 batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 8, 8, 64)     0           add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 64)     147520      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 8, 8, 64)     256         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 8, 8, 64)     0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 64)     147520      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 8, 8, 64)     256         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 8, 8, 64)     0           activation_244[0][0]             \n",
      "                                                                 batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 8, 8, 64)     0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 1, 1, 64)     0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 64)           0           average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           650         flatten_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,077,530\n",
      "Trainable params: 1,076,154\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 689s 441ms/step - loss: 1.5327 - accuracy: 0.5032 - val_loss: 1.9189 - val_accuracy: 0.4674 - lr: 0.0010\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 32, 32, 16)   2368        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 32, 32, 16)   64          conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 32, 32, 16)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 32, 32, 16)   12560       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 32, 32, 16)   64          conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 32, 32, 16)   0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 32, 32, 16)   12560       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 32, 32, 16)   64          conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 32, 32, 16)   0           activation_247[0][0]             \n",
      "                                                                 batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 32, 32, 16)   0           add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 32, 32, 16)   12560       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 32, 32, 16)   64          conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 32, 32, 16)   0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 32, 32, 16)   12560       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 32, 32, 16)   64          conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 32, 32, 16)   0           activation_249[0][0]             \n",
      "                                                                 batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 32, 32, 16)   0           add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 32, 32, 16)   12560       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 32, 32, 16)   64          conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 32, 32, 16)   0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 32, 32, 16)   12560       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 32, 32, 16)   64          conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 32, 32, 16)   0           activation_251[0][0]             \n",
      "                                                                 batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 32, 32, 16)   0           add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 16, 16, 32)   25120       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 16, 16, 32)   128         conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 16, 16, 32)   0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 16, 16, 32)   50208       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 16, 16, 32)   544         activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 16, 16, 32)   128         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 16, 16, 32)   0           conv2d_282[0][0]                 \n",
      "                                                                 batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 16, 16, 32)   0           add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 16, 16, 32)   50208       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 16, 16, 32)   128         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 16, 16, 32)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 16, 16, 32)   50208       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 16, 16, 32)   128         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 16, 16, 32)   0           activation_255[0][0]             \n",
      "                                                                 batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 16, 16, 32)   0           add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 16, 16, 32)   50208       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 16, 16, 32)   128         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 16, 16, 32)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 16, 16, 32)   50208       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 16, 16, 32)   128         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 16, 16, 32)   0           activation_257[0][0]             \n",
      "                                                                 batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 16, 16, 32)   0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 8, 8, 64)     100416      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 8, 8, 64)     256         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 8, 8, 64)     0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 8, 8, 64)     200768      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 8, 8, 64)     2112        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 8, 8, 64)     256         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 8, 8, 64)     0           conv2d_289[0][0]                 \n",
      "                                                                 batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 8, 8, 64)     0           add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 8, 8, 64)     200768      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 8, 8, 64)     256         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 8, 8, 64)     0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 8, 8, 64)     200768      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 8, 8, 64)     256         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 8, 8, 64)     0           activation_261[0][0]             \n",
      "                                                                 batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 8, 8, 64)     0           add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 8, 8, 64)     200768      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 8, 8, 64)     256         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 8, 8, 64)     0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 8, 8, 64)     200768      activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 8, 8, 64)     256         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 8, 8, 64)     0           activation_263[0][0]             \n",
      "                                                                 batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 64)     0           add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 1, 1, 64)     0           activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64)           0           average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10)           650         flatten_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,464,202\n",
      "Trainable params: 1,462,826\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "Not using data augmentation.\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 776s 497ms/step - loss: 1.5571 - accuracy: 0.4968 - val_loss: 1.3960 - val_accuracy: 0.5743 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "for kernel_size in kernel_sizes:\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    # Normalize data.\n",
    "\n",
    "\n",
    "\n",
    "    # If subtract pixel mean is enabled\n",
    "    if SUBTRACT_PIXEL_MEAN:\n",
    "        x_train_mean = np.mean(x_train, axis=0)\n",
    "        x_train -= x_train_mean\n",
    "        x_test -= x_train_mean\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "\n",
    "    # Create the neural network\n",
    "    \n",
    "    #with tf.device('/device:GPU:0'):\n",
    "    model = resnet_v1(input_shape=input_shape, depth=DEPTH, kernel_size=kernel_size)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),\n",
    "                    metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "\n",
    "\n",
    "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                   cooldown=0,\n",
    "                                   patience=5,\n",
    "                                   min_lr=0.5e-6)\n",
    "\n",
    "    callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "    # Run training\n",
    "    # Run training, with or without data augmentation.\n",
    "    if not USE_AUGMENTATION:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=EPOCHS,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True,\n",
    "                  callbacks=callbacks)\n",
    "    \n",
    "        \n",
    "        model.save(f'./keras-model/01db_ResNet20-CIFAR-10_K-{kernel_size}.h5')\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '01d_ResNet20_CIFAR-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ndKh7thgFkqH",
    "outputId": "e2ec1772-9942-4209-ffac-d78e6d2db9e9"
   },
   "outputs": [],
   "source": [
    "        model.save(f'./keras-model/01da_ResNet20-CIFAR-10_K-{kernel_size}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "*continue here if you want to load a pretrained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model_file = './keras-model/01d_ResNet20_CIFAR-10.h5'\n",
    "tf_model = tf.keras.models.load_model(tf_model_file)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate against the test set\n",
    "\n",
    "[Losses Documentation](https://keras.io/api/losses/)\n",
    "\n",
    "\n",
    "We used the `categorical_crossentropy` loss for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:\t 0.9185000061988831\n",
      "Test loss:\t 0.4342728555202484\n"
     ]
    }
   ],
   "source": [
    "score = tf_model.evaluate(x=x_test_normalized, y=y_test, verbose=0)\n",
    "\n",
    "tf_model_loss = score[0]\n",
    "tf_model_accuracy = score[1]\n",
    "\n",
    "print('Test accuracy:\\t', tf_model_accuracy)\n",
    "print('Test loss:\\t', tf_model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a single inference\n",
    "\n",
    "Picks a random image from testset and then runs local inference using the original Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# pick a random image\n",
    "image_no = np.random.randint(10000)\n",
    "\n",
    "# use a single example image from the normalized training set\n",
    "result = tf_model.predict(np.array( [ x_test_normalized[image_no] ] ))\n",
    "\n",
    "plt.imshow(x_test_normalized[image_no].squeeze(), cmap=plt.cm.gray_r)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.bar(np.arange(10), result[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
