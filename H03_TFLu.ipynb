{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H03 Tensorflow Lite Micro Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mbed_project(cmsis=True):\n",
    "    if cmsis:\n",
    "        ! ./helpers/update_mbed_cmsis.sh\n",
    "    else:\n",
    "        ! ./helpers/update_mbed.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbed_selection = widgets.Dropdown(\n",
    "    options=['none', 'cmsis-nn'],\n",
    "    description=\"Select mbed project:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write TF Lite model to the mbed project\n",
    "\n",
    "The TF Lite model is a flatbuffers object which can be converted with `xxd -i` to an C array which can be interpreted by TFLu.\n",
    "\n",
    "```\n",
    "!xxd -i {file} > {file}.cc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfl_model_to_file(tfl_model_file, mbed_dir):\n",
    "    \n",
    "    print(f\"Writing '{tfl_model_file}' to '{mbed_dir}'\")\n",
    "    \n",
    "    # Save the file as a C source file\n",
    "    !xxd -i {tfl_model_file} > {tfl_model_file}.cc\n",
    "\n",
    "    source_file = f'{tfl_model_file}.cc'\n",
    "\n",
    "    with open(source_file,'r') as inFile:\n",
    "        lines = str(inFile.read())\n",
    "\n",
    "    start = lines.find(\"= {\")\n",
    "    end = lines.find(\"};\")\n",
    "    \n",
    "    model_array = f\"const unsigned char g_model_data[] DATA_ALIGN_ATTRIBUTE = {str(lines[start+1:end+2])}\"\n",
    "\n",
    "    model_length = int(lines[lines.find(\"len = \") + 6 : -2])\n",
    "    \n",
    "    target_file = './TFLite-model/model_data.cc'\n",
    "    \n",
    "    footer = f\"\\nconst int g_model_data_len = {model_length};\"\n",
    "    \n",
    "    comment = f\"// This file was created at {datetime.now()}\\n// from the file {tfl_model_file}\\n\\n\"\n",
    "\n",
    "    with open(target_file, \"w\") as outFile:\n",
    "        # write header\n",
    "        with open('./TFLite-model/model_header.cc', \"r\") as header_file:\n",
    "            header = header_file.read()\n",
    "        outFile.write(header)\n",
    "        outFile.write(comment)\n",
    "        outFile.write(model_array)\n",
    "        outFile.write(footer)\n",
    "        \n",
    "        \n",
    "    !mv -f ./TFLite-model/model_data.cc {mbed_dir}/src/model_data.cc\n",
    "    \n",
    "    # verify file and copy by checking the length\n",
    "    with open(f\"{mbed_dir}/src/model_data.cc\", 'r') as file:\n",
    "        for line in file:\n",
    "            pass\n",
    "        last_line = line\n",
    "    \n",
    "    if str(model_length) in line:\n",
    "        print(\"Writing the model was successful.\")\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "        print(\"ERR: Writing the model was not successful.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy a normalized example picture\n",
    "\n",
    "A single image will be written as a constant array to the MCU which then can be used for inference on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_constants(model_name, inferences_per_cycle, image_number, mbed_dir):\n",
    "    target_file = './TFLite-model/constants.cc'\n",
    "    \n",
    "    print(f\"Writing image no. {image_number} to '{mbed_dir}'\")\n",
    "\n",
    "    \n",
    "    comment = f\"\\n// This file was created automatically at {datetime.now()}\\n\\n\"\n",
    "    \n",
    "    with open(target_file, 'w') as outFile:\n",
    "        outFile.write(f\"#define INPUT_LENGTH {INPUT_LENGTH}\\n\\n\")\n",
    "        outFile.write('#include \"constants.h\"\\n\\n')\n",
    "        outFile.write(comment)\n",
    "        outFile.write(f'const char model_name[] = \"{model_name}\";\\n\\n')\n",
    "        outFile.write(f\"const int kInferencesPerCycle = {int(inferences_per_cycle)};\\n\\n\")\n",
    "        outFile.write(f\"const int input_example_label = {int(np.argmax(y_test[image_number]))};\\n\\n\")    \n",
    "        outFile.write(\"const float input_example[INPUT_LENGTH] = {\\n\")\n",
    "        \n",
    "        # flatten image: doesn't matter wether greyscale or RGB\n",
    "        image_flat = x_test_normalized[image_number].flatten()\n",
    "        \n",
    "        for index, value in enumerate(image_flat):\n",
    "            outFile.write(\"%f,\" % value)\n",
    "            if index % 50 == 0:\n",
    "                outFile.write(\"\\n\")\n",
    "        outFile.write(\"};\\n\")\n",
    "\n",
    "    \n",
    "    !mv -f ./TFLite-model/constants.cc {mbed_dir}/src/constants.cc\n",
    "    print(f\"Writing was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further optimization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_fpu(mbed_dir, status):\n",
    "    import fileinput\n",
    "\n",
    "    with fileinput.FileInput(f'{mbed_dir}/mbed-os/tools/toolchains/gcc.py', inplace=True, backup='.bak') as file:\n",
    "        for line in file:\n",
    "            if status == 0:\n",
    "                print(line.replace('core == \"Cortex-M', 'core == \"NOT-TODAY_Cortex-M'), end='')\n",
    "            elif status == 1:\n",
    "                print(line.replace('core == \"NOT-TODAY_Cortex-M', 'core == \"Cortex-M'), end='')\n",
    "            else:\n",
    "                return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_compiler_flag(mbed_dir, flag):\n",
    "    import fileinput\n",
    "\n",
    "    with fileinput.FileInput(f'{mbed_dir}/mbed-os/tools/profiles/release.json', inplace=True, backup='.bak') as file:\n",
    "        for line in file:\n",
    "            if flag == \"-Ofast\":\n",
    "                print(line.replace('\"-Os\"', '\"-Ofast\"'), end='')\n",
    "            elif flag == \"-Os\":\n",
    "                print(line.replace('\"-Ofast\"', '\"-Os\"'), end='')\n",
    "            else:\n",
    "                return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_arena_size(mbed_dir, size_kb):\n",
    "    import fileinput\n",
    "\n",
    "    with fileinput.FileInput(f'{mbed_dir}/src/main_functions.cc', inplace=True, backup='.bak') as file:\n",
    "        for line in file:\n",
    "            print(line.replace(\"constexpr int kTensorArenaSize = \", f\"constexpr int kTensorArenaSize = {size_kb} * 1024; //\"), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Options for the compilations\n",
    "\n",
    "#### Macros\n",
    "\n",
    "A couple of different benchmarking features are implemented via macros. \n",
    "Macros were used to allow for maximal performance and reduce unnecessary functions calls during the runtime.\n",
    "\n",
    "The following macros have been implemented to enable different types of benchmarking and debugging:\n",
    "\n",
    "##### `INPUT_LENGTH=N`\n",
    "\n",
    "Sets the length of NN input. This is important for filling the input tensor.\n",
    "\n",
    "\n",
    "##### `INPUT_TYPE`\n",
    "\n",
    "*not in use yet*\n",
    "\n",
    "\n",
    "##### `OUTPUT_LENGTH=N`\n",
    "\n",
    "This sets the length of NN output -- important for reading the output tensor.\n",
    "\n",
    "##### `OUTPUT_TYPE`\n",
    "\n",
    "*not in use yet*\n",
    "\n",
    "\n",
    "##### `CYCLES`\n",
    "\n",
    "This macro sets the unit of benchmarking to cycles which might allow for more granular precision.\n",
    "The implementation is seen in `benchmark.cc`. \n",
    "\n",
    "Make sure you know the clock frequency of your MCU if you're interested in absolute numbers.\n",
    "\n",
    "The default unit is microseconds (us).\n",
    "\n",
    "\n",
    "##### `BENCHMARK_LAYERS`\n",
    "\n",
    "Setting this macro enables the individual benchmark of single layers.\n",
    "The benchmarking of a whole of batch of inference gets disabled.\n",
    "The MCU will report the benchmarking results for each layers of the neural network.\n",
    "\n",
    "\n",
    "##### `NO_REPORTING`\n",
    "\n",
    "\n",
    "This macro disables the output of the predictions made by the NN and benchmarking result.\n",
    "\n",
    "\n",
    "##### `NO_MANUAL_INPUT`\n",
    "\n",
    "This macro disables the manual input of input data.\n",
    "The inference will loop indefinitely with the provided input data in `constants.cc`.\n",
    "\n",
    "##### `BAUDRATE=N`\n",
    "\n",
    "Sets the baud rate of the UART interface. \n",
    "Plays a significant role for the duration of the verfication of the testset on the MCU itself.\n",
    "\n",
    "##### `ENERGY_MEASUREMENT`\n",
    "\n",
    "Disables LEDs which indicate the current status.\n",
    "Necessary for not falsifying energy measurements.\n",
    "\n",
    "Furthermore it enables toggling GPIOs for the current status of the inference.\n",
    "\n",
    "\n",
    "| GPIO  \t| Indicates      \t|\n",
    "|-------\t|-----------------\t|\n",
    "| D0\t \t| Inference Status \t|\n",
    "| D1\t\t| Layer Status     \t|\n",
    "| D2     \t| Input Status     \t|\n",
    "| D3     \t|  *not used yet* \t|\n",
    "\n",
    "Pin names can be found under `mbed-os/targets/TARGET_STM/TARGET_STM32L4/TARGET_STM32L496xG/TARGET_NUCLEO_L496ZG/PinNames.h` - depending on the target board.\n",
    "\n",
    "When `BENCHMARK_LAYERS` is also enabled the GPIO D1 gets triggered and a waiting time of 500ms is introduced between each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_target(target):\n",
    "    global target_mcu\n",
    "    target_mcu = target\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences_slider = widgets.FloatLogSlider(\n",
    "    value=1,\n",
    "    base=10,\n",
    "    min=0, # max exponent of base\n",
    "    max=4, # min exponent of base\n",
    "    step=1, # exponent step\n",
    "    description='No of repetition per inference'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cycles_selection = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Benchmark in cycles (instead of us)',\n",
    "    indent=False\n",
    ")\n",
    "layers_selection = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Benchmark with layer granularity (instead of a whole inference)',\n",
    "    indent=False\n",
    ")\n",
    "reporting_selection = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Report the results of the inference via UART',\n",
    "    indent=False\n",
    ")\n",
    "input_selection = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Enabling custom input via UART (required for automated verification)',\n",
    "    indent=False\n",
    ")\n",
    "energy_selection = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Enable custom settings for an energy measurement',\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "baudrate_slider = widgets.FloatLogSlider(\n",
    "    value=10e6,\n",
    "    base=10,\n",
    "    min=4, # max exponent of base\n",
    "    max=6, # min exponent of base\n",
    "    step=1, # exponent step\n",
    "    description='Baudrate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_compilation_macros(input_length, output_length, baudrate=1000000,\n",
    "               cycles=False, layers=False, reporting=True,\n",
    "               manual_input=True, energy=False):\n",
    "    \n",
    "    arguments = ''\n",
    "    arguments += f'-D INPUT_LENGTH={input_length} '\n",
    "    arguments += f'-D OUTPUT_LENGTH={output_length} '\n",
    "    arguments += f'-D BAUDRATE={baudrate} '\n",
    "    \n",
    "    if cycles:\n",
    "        arguments += '-D CYCLES '\n",
    "    if layers:\n",
    "        arguments += '-D BENCHMARK_LAYERS '\n",
    "    if not reporting:\n",
    "        arguments += '-D NO_REPORTING '\n",
    "    if not manual_input:\n",
    "        arguments += '-D NO_MANUAL_INPUT '\n",
    "    if energy:\n",
    "        arguments += '-D ENERGY_MEASUREMENT '\n",
    "    \n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_information(filename, series):\n",
    "    if \"PRUNED\" in filename:\n",
    "        series['pruned'] = 1\n",
    "    else:\n",
    "        series['pruned'] = 0\n",
    "    if \"optimized\" in filename:\n",
    "        series['weights'] = 'int8'\n",
    "        series['activations'] = 'float32'\n",
    "    elif \"INT8\" in filename:\n",
    "        series['weights'] = 'int8'\n",
    "        series['activations'] = 'int8'\n",
    "    else:\n",
    "        series['weights'] = 'float32'\n",
    "        series['activations'] = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imported helper functions from H03_TFLu.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
