{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all modules.\n",
      "\tTensorflow Version:  2.2.0\n",
      "\tNumpy Version:  1.19.0\n",
      "\tPandas Version:  1.0.5\n"
     ]
    }
   ],
   "source": [
    "%run '00_README.ipynb'\n",
    "%run 'H01_Models.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac752e26862a4c0cb165c0344e245bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select model:', options=('keras-model/01a_LeNet-MNIST.h5', 'keras-model/01b_ResNet20_CIFâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selection = widgets.Dropdown(\n",
    "    options=glob.glob(\"keras-model/*.h5\"),\n",
    "    description='Select model:',\n",
    ")\n",
    "display(model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_model_file = model_selection.value\n",
    "tf_model = tf.keras.models.load_model(tf_model_file)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Lite: Conversion\n",
    "\n",
    "[Converter Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter)\n",
    "\n",
    "[More Converter Documentation for TF 2.2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/index.md)\n",
    "\n",
    "[Tensorflow Blog about Integer Quantization](https://blog.tensorflow.org/2019/06/tensorflow-integer-quantization.html)\n",
    "\n",
    "![Optimizations Flowchart](https://www.tensorflow.org/lite/performance/images/optimization.jpg)\n",
    "\n",
    "\n",
    "### Dynamic range quantization\n",
    "The simplest form of post-training quantization statically quantizes only the weights from floating point to integer, which has 8-bits of precision.\n",
    "\n",
    "At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency.\n",
    "\n",
    "To further improve latency, \"dynamic-range\" operators dynamically quantize activations based on their range to 8-bits and perform computations with 8-bit weights and activations. This optimization provides latencies close to fully fixed-point inference. However, the outputs are still stored using floating point, so that the speedup with dynamic-range ops is less than a full fixed-point computation. Dynamic-range ops are available for the most compute-intensive operators in a network:\n",
    "\n",
    "    tf.keras.layers.Dense\n",
    "    tf.keras.layers.Conv2D\n",
    "    tf.keras.layers.LSTM\n",
    "    tf.nn.embedding_lookup\n",
    "    tf.compat.v1.nn.rnn_cell.BasicRNNCell\n",
    "    tf.compat.v1.nn.bidirectional_dynamic_rnn\n",
    "    tf.compat.v1.nn.dynamic_rnn\n",
    "    \n",
    "**Unsure if this is available in TF Lite Micro yet.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the optimizations\n",
    "\n",
    "#### Default optimization strategy.\n",
    "\n",
    "Converter will do its best to improve size and latency based on the\n",
    "information provided.\n",
    "Enhanced optimizations can be gained by providing a representative_dataset.\n",
    "This is recommended, and is currently equivalent to the modes below.\n",
    "Currently, weights will be quantized and if representative_dataset is\n",
    "provided, activations for quantizable operations will also be quantized.\n",
    "\n",
    "`DEFAULT = \"DEFAULT\"`\n",
    "\n",
    "#### Optimize for size.\n",
    "\n",
    "Optimizations that reduce the size of the model.\n",
    "The model size will be reduced.\n",
    "Currently, weights will be quantized and if representative_dataset is\n",
    "provided, activations for quantizable operations will also be quantized.\n",
    "\n",
    "`OPTIMIZE_FOR_SIZE = \"OPTIMIZE_FOR_SIZE\"`\n",
    "\n",
    "#### Optimize for latency.\n",
    "\n",
    "Optimizations that reduce the latency of the model.\n",
    "Currently, weights will be quantized and if representative_dataset is\n",
    "provided, activations for quantizable operations will also be quantized.\n",
    "\n",
    "`OPTIMIZE_FOR_LATENCY = \"OPTIMIZE_FOR_LATENCY\"`\n",
    "\n",
    "\n",
    "\n",
    "**-> All modes are equivalent and this is proven by running `diff` on them (see blow). Furthermore it is mentioned [here](https://github.com/tensorflow/tensorflow/blob/570206441717511720fdae9ac58dac16cc1d348a/tensorflow/lite/python/lite.py#L96).**\n",
    "\n",
    "\n",
    "Therefore the following code snippet does **not** generate a different result than `converter.optimizations = [tf.lite.Optimize.DEFAULT]` at the moment.\n",
    "\n",
    "```python\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_size.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_latency.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the `OpsSet`\n",
    "[Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/OpsSet)\n",
    "\n",
    "Enum class defining the sets of ops available to generate TFLite models.\n",
    "\n",
    "`SELECT_TF_OPS`:\n",
    "Convert model using TensorFlow ops. Not all TensorFlow ops are available.\n",
    "WARNING: Experimental interface, subject to change.\n",
    "\n",
    "`TFLITE_BUILTINS`:\n",
    "Convert model using TensorFlow Lite builtin ops.\n",
    "\n",
    "\n",
    "\n",
    "`TFLITE_BUILTINS_INT8`:\n",
    "Convert model using only TensorFlow Lite quantized int8 operations.\n",
    "Specifying this will throw an error for operations that do not yet have quantized implementations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About `TargetSpec`\n",
    "[Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TargetSpec)\n",
    "\n",
    "Details about target device. Converter optimizes the generated model for specific device.\n",
    "Attributes\n",
    "\n",
    "`supported_ops`: Experimental flag, subject to change. Set of OpsSet options supported by the device. (default set(`[OpsSet.TFLITE_BUILTINS])`)\n",
    "\n",
    "`supported_types`: List of types for constant values on the target device. Supported values are types exported by lite.constants. Frequently, an optimization choice is driven by the most compact (i.e. smallest) type in this list (default `[constants.FLOAT]`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*todo*\n",
    "```\n",
    "import tensorflow_model_optimization as tfmot\n",
    "model = tfmot.quantization.keras.quantize_annotate_model(model)\n",
    "```\n",
    "https://stackoverflow.com/questions/62433410/tensorflow-fake-quantize-layers-are-also-called-from-tf-lite/62524147\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# This one is still using foat32.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNet-MNIST.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# stores only the weights as 8-bit integers\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "# At inference, weights are converted from 8-bits of precision to \n",
    "# floating point and computed using floating-point kernels. \n",
    "# This conversion is done once and cached to reduce latency.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNet-MNIST_default.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Experimental flag, subject to change. \n",
    "# Enables MLIR-based conversion instead of TOCO conversion. \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_experimental.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Parameters are quantized to float16\n",
    "# Model is still executed in float32\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_float16.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer Quantization\n",
    "\n",
    "To do this, we need to measure the dynamic range of activations and inputs with a representative data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_representative_dataset():\n",
    "  for x in x_train_normalized[:5000]:\n",
    "    yield [np.array([x], dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_partial_int8ops.tflite', 'wb').write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-int8 quantization\n",
    "\n",
    "So to ensure that the converted model is fully quantized (make the converter throw an error if it encounters an operation it cannot quantize), and to use integers for the model's input and output, you need to convert the model again using these additional configurations:\n",
    "```python\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Enforce full-int8 quantization (except inputs/outputs which are always float)\n",
    "# So to ensure that the converted model is fully quantized \n",
    "# (make the converter throw an error if it encounters an operation it cannot quantize), \n",
    "# and to use integers for the model's input and output, \n",
    "# you need to convert the model again using these additional configurations:\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = yield_representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_int8ops.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "\n",
    "# Note: The converter will throw an error\n",
    "# if it encounters an operation it cannot currently quantize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also quantizes the input and output.\n",
    "However, this is currently not implemented in TF 2.2 see [here](https://github.com/tensorflow/tensorflow/issues/38285)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "converter.representative_dataset = yield_representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "open('./TFLite-model/LeNET-MNIST_int8ops+inout.tflite', 'wb').write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate all available models\n",
    "\n",
    "This script generates a combination of all available models. Nonetheless most of them are competly similiar due to missing implementations.\n",
    "\n",
    "See below for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "def yield_representative_dataset():\n",
    "  for x in x_train_normalized[:5000]:\n",
    "    yield [np.array([x], dtype=np.float32)]\n",
    "\n",
    "\n",
    "optimizations = {\n",
    "    \"none\": None,\n",
    "    \"optimized\": [tf.lite.Optimize.DEFAULT]\n",
    "}# all optmizations are currently equal\n",
    "\n",
    "supported_ops = {\n",
    "    \"tflite-builtins\": [tf.lite.OpsSet.TFLITE_BUILTINS],\n",
    "    \"tflite-builtins-INT8\": [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "}\n",
    "\n",
    "datatypes = {\n",
    "    \"none\": None,\n",
    "    \"float32\": [tf.float32],\n",
    "    \"float16\": [tf.float16],\n",
    "    \"int8\": [tf.int8],\n",
    "    \"int16\": [tf.int16],\n",
    "    \"int32\": [tf.int32]\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    \"none\": None,\n",
    "    \"dataset\": yield_representative_dataset\n",
    "}\n",
    "\n",
    "# Not implemented yet in TF 2.2\n",
    "# input_type = [None, tf.float32, tf.float16,2 tf.int8, tf.int32]\n",
    "# output_type = [None, tf.float32, tf.float16, tf.int8, tf.int32]\n",
    "\n",
    "\n",
    "for xopt in optimizations:\n",
    "    for xop in supported_ops:\n",
    "        for xtype in datatypes:\n",
    "            for xset in datasets:\n",
    "                \n",
    "                converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "                \n",
    "                if optimizations[xopt]:\n",
    "                    converter.optimizations = optimizations[xopt]\n",
    "                \n",
    "                if supported_ops[xop]:\n",
    "                    converter.target_spec.supported_ops = supported_ops[xop]\n",
    "                \n",
    "                if datatypes[xtype]:\n",
    "                    converter.target_spec.supported_types = datatypes[xtype]\n",
    "\n",
    "                \n",
    "                if datasets[xset]:\n",
    "                    converter.representative_dataset = datasets[xset]\n",
    "\n",
    "                # catch impossible combinations - e.g.  \n",
    "                # ValueError: representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.\n",
    "                # ValueError TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.\n",
    "                try:\n",
    "                    tflite_model = converter.convert()\n",
    "                    open(f'./TFLite-model/all/{model_name}_{xopt}_{xop}_{xtype}_{xset}.tflite', 'wb').write(tflite_model)\n",
    "                except Exception as e:\n",
    "                    tflite_model = bytes(str(e).encode('utf-8'))\n",
    "                    open(f'./TFLite-model/all/ERR_{model_name}_{xopt}_{xop}_{xtype}_{xset}.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check which files are identical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_float16_dataset.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_float16_none.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_float32_dataset.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_float32_none.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_int16_dataset.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_int16_none.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_int32_dataset.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_int32_none.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_none_dataset.tflite\n",
      "069f0bfaa4b6e6f04876f46483d0e5e8 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_none_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_none_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_none_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_none_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_int8_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_none_none.tflite\n",
      "43651801321d464dd5e16e8a7b780f05 ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins_int8_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_float16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_float16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_float32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_float32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_float16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_float16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_float32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_float32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_float16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_float16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_float32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_float32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_int16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_int16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_int32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_none_tflite-builtins-INT8_int32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_float16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_float16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_float32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_float32_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_int16_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_int16_none.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_int32_dataset.tflite\n",
      "541d73b45e3e76418dfb76d67ccdbada ./TFLite-model/all/ERR_LeNet-MNIST_optimized_tflite-builtins-INT8_int32_none.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_float16_dataset.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_float16_none.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_float32_dataset.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_float32_none.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_int16_dataset.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_int16_none.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_int32_dataset.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_int32_none.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_none_dataset.tflite\n",
      "60e8b4cf816220d7282af9e95f3f1be1 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_none_none.tflite\n",
      "77405a63fadafb68d66a69deb7624ea5 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_float16_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins-INT8_int8_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_int8_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins-INT8_int8_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins-INT8_none_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_float32_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_int16_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_int32_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_int8_dataset.tflite\n",
      "8420dd51078b08b0b9a5cb5308b7ec15 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_none_dataset.tflite\n",
      "b5d36940a20d4c9f2a084b47a55bc475 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_float16_none.tflite\n",
      "c9ea19f165230d22a6c87d4cfacf98a2 ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_float16_none.tflite\n",
      "ec7cd8d9f7db2a784ac8588874f8526d ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_float32_none.tflite\n",
      "ec7cd8d9f7db2a784ac8588874f8526d ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_int16_none.tflite\n",
      "ec7cd8d9f7db2a784ac8588874f8526d ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_int32_none.tflite\n",
      "ec7cd8d9f7db2a784ac8588874f8526d ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_none_none.tflite\n",
      "f16060df7b6b24802f403780d7f6e47d ./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_float16_dataset.tflite\n",
      "fa7a887233661617ff175014afec8a9e ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_float32_none.tflite\n",
      "fa7a887233661617ff175014afec8a9e ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_int16_none.tflite\n",
      "fa7a887233661617ff175014afec8a9e ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_int32_none.tflite\n",
      "fa7a887233661617ff175014afec8a9e ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_none_none.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_int8_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_int8_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_int8_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins-INT8_none_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_float32_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_int16_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_int32_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_int8_dataset.tflite\n",
      "ffabc658814a6adbf88a839afaeed0a1 ./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_none_dataset.tflite\n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "!find ./TFLite-model/all/*{model_name}*.tflite -type f | xargs md5 -r | sort -k1,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes:\n",
    "- using no `converter.optimizations` always results in the same model - all the options get ignored\n",
    "- except setting `TFLITE-BUILTINS-INT8` results in the same model when a `representative_dataset` is provided\n",
    "- providing no `representative_dataset` results in the same model, also for different `types`\n",
    "- `LeNet-MNIST_optimized_tflite-builtins_float16_dataset.tflite` seems to be an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare all files to a single one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "%%bash\n",
    "for i in ./TFLite-model/all/*.tflite; do diff -q \"$i\" ./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_none_none.tflite; done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving relevant models\n",
    "\n",
    "For Tensorflow Lite Micro (TFLu) the float16 model isn't supported.\n",
    "\n",
    "```\n",
    "Type FLOAT16 (10) not is not supported\n",
    "Failed to initialize tensor 1\n",
    "MicroAllocator: Failed to initialize.\n",
    "AllocateTensors() failed\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "%%bash\n",
    "\n",
    "files=(\"./TFLite-model/all/LeNet-MNIST_none_tflite-builtins_none_none.tflite\"\n",
    "       \"./TFLite-model/all/LeNet-MNIST_none_tflite-builtins-INT8_none_dataset.tflite\"\n",
    "       \"./TFLite-model/all/LeNet-MNIST_optimized_tflite-builtins_none_none.tflite\"\n",
    "       \"./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins_none_none.tflite\"\n",
    "       \"./TFLite-model/all/LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_none_dataset.tflite\"\n",
    "       \"./TFLite-model/all/LeNet-MNIST_PRUNED_optimized_tflite-builtins_none_none.tflite\")\n",
    "\n",
    "for f in ${files[@]}; do cp ${f} ./TFLite-model/; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "%%bash\n",
    "\n",
    "files=(\"./TFLite-model/all/01b_ConvNet-CIFAR-10_none_tflite-builtins_none_none.tflite\"\n",
    "       \"./TFLite-model/all/01b_ConvNet-CIFAR-10_none_tflite-builtins-INT8_none_dataset.tflite\"\n",
    "       \"./TFLite-model/all/01b_ConvNet-CIFAR-10_optimized_tflite-builtins_none_none.tflite\")\n",
    "\n",
    "for f in ${files[@]}; do cp ${f} ./TFLite-model/; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "%%bash\n",
    "\n",
    "files=(\"./TFLite-model/all/01d_ResNet20_CIFAR-10_none_tflite-builtins_none_none.tflite\"\n",
    "       \"./TFLite-model/all/01d_ResNet20_CIFAR-10_none_tflite-builtins-INT8_none_dataset.tflite\"\n",
    "       \"./TFLite-model/all/01d_ResNet20_CIFAR-10_optimized_tflite-builtins_none_none.tflite\")\n",
    "\n",
    "for f in ${files[@]}; do cp ${f} ./TFLite-model/; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check their md5's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "%%bash\n",
    "for file in ./TFLite-model/*.tflite; do\n",
    "    if [[ -f \"$file\" ]]; then\n",
    "        md5 -r -- \"$file\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on quantizing with TF Lite\n",
    "- [Documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/quantization.md)\n",
    "- [Full integer quantization of weights and activations](https://www.tensorflow.org/lite/convert/quantization)\n",
    "- [Quantization Specification](https://www.tensorflow.org/lite/performance/quantization_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesize differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model_file = f'./TFLite-model/{model_name}_none_tflite-builtins_none_none.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(tfl_model_file, basic_model_file='./TFLite-model/LeNet-MNIST_none_tflite-builtins_none_none.tflite', gzip=False):\n",
    "    \n",
    "    basic_model_size = os.path.getsize(basic_model_file) / 1024\n",
    "    \n",
    "    if gzip:\n",
    "        import zipfile\n",
    "        zipped_file = './keras-model/temp_zipped.zip'\n",
    "        with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "            f.write(tfl_model_file)\n",
    "        model_size = os.path.getsize(zipped_file) / 1024\n",
    "        \n",
    "    else:\n",
    "        model_size = os.path.getsize(tfl_model_file) / 1024\n",
    "        \n",
    "    reduction = 100*((basic_model_size - model_size) / basic_model_size)\n",
    "    \n",
    "    return model_size, reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "tfl_files = glob.glob(f'./TFLite-model/*{model_name}*.tflite')\n",
    "\n",
    "for tfl_file in tfl_files:\n",
    "    model_size, reduction = get_size(tfl_file, basic_model_file=basic_model_file)\n",
    "    print(f\"{tfl_file[14:]:<40}\" + \n",
    "          \"{:>20}\".format(\"%10d KiB\" %model_size) + \n",
    "          \"{:>20}\".format(\"(%.2f%% smaller)\" %reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "tfl_files = glob.glob(f'./TFLite-model/*{model_name}*.tflite')\n",
    "\n",
    "for tfl_file in tfl_files:\n",
    "    model_size, reduction = get_size(tfl_file, basic_model_file=basic_model_file, gzip=True)\n",
    "    print(f\"{tfl_file[14:]:<40}\" + \n",
    "          \"{:>10}\".format(\"%10d KiB\" %model_size) + \n",
    "          \"{:>10}\".format(\"(%.2f%% smaller)\" %reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 nope  staff   130K Jul 18 14:55 ./TFLite-model/01b_ConvNet_CIFAR-10_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "-rw-r--r--  1 nope  staff   482K Jul 18 14:55 ./TFLite-model/01b_ConvNet_CIFAR-10_none_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff   128K Jul 18 14:55 ./TFLite-model/01b_ConvNet_CIFAR-10_optimized_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff   320K Jul 18 14:50 ./TFLite-model/01d_ResNet20_CIFAR-10_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "-rw-r--r--  1 nope  staff   1.1M Jul 18 14:50 ./TFLite-model/01d_ResNet20_CIFAR-10_none_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--@ 1 nope  staff   298K Jul 18 14:50 ./TFLite-model/01d_ResNet20_CIFAR-10_optimized_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff    85K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_PRUNED_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "-rw-r--r--  1 nope  staff   320K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_PRUNED_none_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff    89K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_PRUNED_optimized_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff    85K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_none_tflite-builtins-INT8_none_dataset.tflite\n",
      "-rw-r--r--  1 nope  staff   320K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_none_tflite-builtins_none_none.tflite\n",
      "-rw-r--r--  1 nope  staff    89K Aug 27 11:35 ./TFLite-model/LeNet-MNIST_optimized_tflite-builtins_none_none.tflite\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./TFLite-model/*tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with TFLite Interpreter\n",
    "[Interpreter Documentation](https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc614c94a5a4d819d9bbda13e301248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model Type:', options=('./TFLite-model/LeNet-MNIST_none_tflite-builtins_none_none.tfliteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfl_files = glob.glob(f'./TFLite-model/*{model_name}*.tflite')\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=tfl_files,\n",
    "    description='Model Type:'\n",
    ")\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(tfl_model_file):\n",
    "    \n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "\n",
    "    # input_shape = input_details[0]['shape']\n",
    "    # print(\"\\ninput_shape: \", input_shape)\n",
    "\n",
    "    # output_shape = output_details[0]['shape']\n",
    "    # print(\"\\noutput_shape: \", output_shape)\n",
    "\n",
    "    return input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_details(tfl_model_file):\n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    tensor_details = model.get_tensor_details()\n",
    "\n",
    "    return tensor_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Get the input and output tensors so we can feed in values and get the results\n",
    "for model_file in tfl_files:\n",
    "    input_details, output_details = get_details(model_file)\n",
    "\n",
    "    print(\"\\ninput_details\\n\", input_details)\n",
    "    print(\"\\noutput_details\\n\", output_details)\n",
    "    print('------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = tfl_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details, output_details = get_details(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'conv2d_4_input_int8',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 32, 32,  1], dtype=int32),\n",
       "  'shape_signature': array([ 1, 32, 32,  1], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_4/BiasAdd/ReadVariableOp',\n",
       "  'index': 1,\n",
       "  'shape': array([6], dtype=int32),\n",
       "  'shape_signature': array([6], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([2.9294801e-05, 2.2570026e-05, 2.3931141e-05, 1.6446251e-11,\n",
       "          2.5747768e-05, 2.6919668e-05], dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_5/BiasAdd/ReadVariableOp',\n",
       "  'index': 2,\n",
       "  'shape': array([16], dtype=int32),\n",
       "  'shape_signature': array([16], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([5.2103816e-05, 4.1569194e-05, 3.0372510e-05, 2.6957849e-05,\n",
       "          3.4160599e-05, 3.1145068e-05, 6.2019477e-05, 3.5473160e-05,\n",
       "          4.8123318e-05, 4.4229306e-05, 5.4571792e-05, 4.7736288e-05,\n",
       "          3.5989113e-05, 3.1044427e-05, 5.8127131e-05, 3.8056667e-05],\n",
       "         dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_6/BiasAdd/ReadVariableOp',\n",
       "  'index': 3,\n",
       "  'shape': array([120], dtype=int32),\n",
       "  'shape_signature': array([120], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (9.650874562794343e-05, 0),\n",
       "  'quantization_parameters': {'scales': array([9.6508746e-05], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_7/BiasAdd/ReadVariableOp',\n",
       "  'index': 4,\n",
       "  'shape': array([84], dtype=int32),\n",
       "  'shape_signature': array([84], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0001878465700428933, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00018785], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_8/BiasAdd/ReadVariableOp',\n",
       "  'index': 5,\n",
       "  'shape': array([10], dtype=int32),\n",
       "  'shape_signature': array([10], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0004560302768368274, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00045603], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/flatten_2/Const',\n",
       "  'index': 6,\n",
       "  'shape': array([2], dtype=int32),\n",
       "  'shape_signature': array([2], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_6/MatMul',\n",
       "  'index': 7,\n",
       "  'shape': array([120, 576], dtype=int32),\n",
       "  'shape_signature': array([120, 576], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.005802906583994627, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00580291], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_7/MatMul',\n",
       "  'index': 8,\n",
       "  'shape': array([ 84, 120], dtype=int32),\n",
       "  'shape_signature': array([ 84, 120], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.005442619789391756, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00544262], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_8/MatMul',\n",
       "  'index': 9,\n",
       "  'shape': array([10, 84], dtype=int32),\n",
       "  'shape_signature': array([10, 84], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00603761849924922, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00603762], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_4/Conv2D',\n",
       "  'index': 10,\n",
       "  'shape': array([6, 3, 3, 1], dtype=int32),\n",
       "  'shape_signature': array([6, 3, 3, 1], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([7.4701738e-03, 5.7553565e-03, 6.1024404e-03, 4.1937938e-09,\n",
       "          6.5656803e-03, 6.8645151e-03], dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_5/Conv2D',\n",
       "  'index': 11,\n",
       "  'shape': array([16,  3,  3,  6], dtype=int32),\n",
       "  'shape_signature': array([16,  3,  3,  6], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([0.0054735 , 0.00436684, 0.00319063, 0.00283192, 0.00358857,\n",
       "          0.00327179, 0.00651514, 0.00372645, 0.00505535, 0.00464628,\n",
       "          0.00573276, 0.00501469, 0.00378065, 0.00326121, 0.00610625,\n",
       "          0.00399785], dtype=float32),\n",
       "   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_4/Relu;sequential_2/conv2d_4/BiasAdd;sequential_2/conv2d_4/Conv2D;sequential_2/conv2d_4/BiasAdd/ReadVariableOp',\n",
       "  'index': 12,\n",
       "  'shape': array([ 1, 30, 30,  6], dtype=int32),\n",
       "  'shape_signature': array([ 1, 30, 30,  6], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.009519286453723907, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00951929], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/average_pooling2d_4/AvgPool',\n",
       "  'index': 13,\n",
       "  'shape': array([ 1, 15, 15,  6], dtype=int32),\n",
       "  'shape_signature': array([ 1, 15, 15,  6], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.009519286453723907, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00951929], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/conv2d_5/Relu;sequential_2/conv2d_5/BiasAdd;sequential_2/conv2d_5/Conv2D;sequential_2/conv2d_5/BiasAdd/ReadVariableOp',\n",
       "  'index': 14,\n",
       "  'shape': array([ 1, 13, 13, 16], dtype=int32),\n",
       "  'shape_signature': array([ 1, 13, 13, 16], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.016631104052066803, -128),\n",
       "  'quantization_parameters': {'scales': array([0.0166311], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/average_pooling2d_5/AvgPool',\n",
       "  'index': 15,\n",
       "  'shape': array([ 1,  6,  6, 16], dtype=int32),\n",
       "  'shape_signature': array([ 1,  6,  6, 16], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.016631104052066803, -128),\n",
       "  'quantization_parameters': {'scales': array([0.0166311], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/flatten_2/Reshape',\n",
       "  'index': 16,\n",
       "  'shape': array([  1, 576], dtype=int32),\n",
       "  'shape_signature': array([  1, 576], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.016631104052066803, -128),\n",
       "  'quantization_parameters': {'scales': array([0.0166311], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_6/Relu;sequential_2/dense_6/BiasAdd',\n",
       "  'index': 17,\n",
       "  'shape': array([  1, 120], dtype=int32),\n",
       "  'shape_signature': array([  1, 120], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.03451399877667427, -128),\n",
       "  'quantization_parameters': {'scales': array([0.034514], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_7/Relu;sequential_2/dense_7/BiasAdd',\n",
       "  'index': 18,\n",
       "  'shape': array([ 1, 84], dtype=int32),\n",
       "  'shape_signature': array([ 1, 84], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0755314826965332, -128),\n",
       "  'quantization_parameters': {'scales': array([0.07553148], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential_2/dense_8/BiasAdd',\n",
       "  'index': 19,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([ 1, 10], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.20506790280342102, 42),\n",
       "  'quantization_parameters': {'scales': array([0.2050679], dtype=float32),\n",
       "   'zero_points': array([42], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity_int8',\n",
       "  'index': 20,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([ 1, 10], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00390625, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'conv2d_4_input',\n",
       "  'index': 21,\n",
       "  'shape': array([ 1, 32, 32,  1], dtype=int32),\n",
       "  'shape_signature': array([ 1, 32, 32,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity',\n",
       "  'index': 22,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([ 1, 10], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_layer_details(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is particular important for the deployment on the microcontroller, as our input and output tensor have to match the datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis with tflite_analyser\n",
    "Make sure to install [tflite_analyser](https://github.com/PeteBlackerThe3rd/tflite_analyser) and its dependencies and point to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "====== Reading flatbuffer \"./TFLite-model/LeNet-MNIST_none_tflite-builtins_none_none.tflite\" ======\n",
      "===================================================================================================\n",
      "Done.\n",
      "Analysing graph[0] - b'main'\n",
      "\n",
      "Operation types used by graph 0:\n",
      "CONV_2D         version  1 (builtin)\n",
      "AVERAGE_POOL_2D version  1 (builtin)\n",
      "RESHAPE         version  1 (builtin)\n",
      "FULLY_CONNECTED version  1 (builtin)\n",
      "SOFTMAX         version  1 (builtin)\n",
      "\n",
      "Weights Summary:\n",
      "\n",
      "11 Weight tensors, containing 81,196 weights, taking 317 Kilobytes\n",
      "\n",
      "           81,194    FLOAT32 weights taking 317 Kilobytes\n",
      "                2      INT32 weights taking 8 Bytes\n",
      "\n",
      "Weights Details                                  type     --- (shape) ---      size      \n",
      "-----------------------------------------------------------------------------------------\n",
      "sequential_2/conv2d_4/BiasAdd/ReadVariableOp   FLOAT32    (6)             24 Bytes      \n",
      "sequential_2/conv2d_5/BiasAdd/ReadVariableOp   FLOAT32    (16)            64 Bytes      \n",
      "sequential_2/dense_6/BiasAdd/ReadVariableOp    FLOAT32    (120)           480 Bytes     \n",
      "sequential_2/dense_7/BiasAdd/ReadVariableOp    FLOAT32    (84)            336 Bytes     \n",
      "sequential_2/dense_8/BiasAdd/ReadVariableOp    FLOAT32    (10)            40 Bytes      \n",
      "sequential_2/flatten_2/Const                    INT32     (2)             8 Bytes       \n",
      "sequential_2/dense_6/MatMul                    FLOAT32    (120, 576)      270 Kilobytes \n",
      "sequential_2/dense_7/MatMul                    FLOAT32    (84, 120)       39.4 Kilobytes\n",
      "sequential_2/dense_8/MatMul                    FLOAT32    (10, 84)        3.28 Kilobytes\n",
      "sequential_2/conv2d_4/Conv2D                   FLOAT32    (6, 3, 3, 1)    216 Bytes     \n",
      "sequential_2/conv2d_5/Conv2D                   FLOAT32    (16, 3, 3, 6)   3.38 Kilobytes\n",
      "\n",
      "Dynamic tensors requiring memory allocation.\n",
      "\n",
      "This model contains 9 operations.\n",
      "\n",
      "    Tensor Name                                                                                                                           (Size Bytes)  [Generating Op]  [Final Use Op]\n",
      "sequential_2/conv2d_4/Relu;sequential_2/conv2d_4/BiasAdd;sequential_2/conv2d_4/Conv2D;sequential_2/conv2d_4/BiasAdd/ReadVariableOp  (     21600)       [   0]         [   1]\n",
      "sequential_2/average_pooling2d_4/AvgPool                                                                                            (      5400)       [   1]         [   2]\n",
      "sequential_2/conv2d_5/Relu;sequential_2/conv2d_5/BiasAdd;sequential_2/conv2d_5/Conv2D;sequential_2/conv2d_5/BiasAdd/ReadVariableOp  (     10816)       [   2]         [   3]\n",
      "sequential_2/average_pooling2d_5/AvgPool                                                                                            (      2304)       [   3]         [   4]\n",
      "sequential_2/flatten_2/Reshape                                                                                                      (      2304)       [   4]         [   5]\n",
      "sequential_2/dense_6/Relu;sequential_2/dense_6/BiasAdd                                                                              (       480)       [   5]         [   6]\n",
      "sequential_2/dense_7/Relu;sequential_2/dense_7/BiasAdd                                                                              (       336)       [   6]         [   7]\n",
      "sequential_2/dense_8/BiasAdd                                                                                                        (        40)       [   7]         [   8]\n",
      "\n",
      "Graph contains 21 tensors\n",
      "\n",
      "[ToDo] (Input) shape[1] op_range (None-0 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[6] op_range (None-0 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,6] op_range (None-2 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,2,0] op_range (None-5 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[8,4] op_range (None-6 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,0] op_range (None-7 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[2] op_range (None-4 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[5,7,6] op_range (None-5 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,2,0] op_range (None-6 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[8,4] op_range (None-7 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[1] op_range (None-0 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[6] op_range (None-2 : None) deps: 1\n",
      "[ToDo] (Intermediate) shape[6] op_range (0-1 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[6] op_range (1-2 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,6] op_range (2-3 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,6] op_range (3-4 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[5,7,6] op_range (4-5 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,2,0] op_range (5-6 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[8,4] op_range (6-7 : 2) deps: 1\n",
      "[ToDo] (Intermediate) shape[1,0] op_range (7-8 : 2) deps: 1\n",
      "[ToDo] (Output) shape[1,0] op_range (8-None : None) deps: 0\n",
      "\n",
      "Operations used by graph 0:\n",
      "TODO\n"
     ]
    }
   ],
   "source": [
    "!python3 ~/masterthesis/tflite_analyser/tflite_analyser.py {model_file} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke selected model for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_inference(tfl_model_file):\n",
    "    input_data = np.array(x_test_normalized[image_no:image_no+1], dtype=np.float32)\n",
    "\n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    input_details, output_details = get_details(tfl_model_file)\n",
    "    model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    model.invoke()\n",
    "    model_prediction = model.get_tensor(output_details[0]['index'])\n",
    "    model.reset_all_variables()\n",
    "\n",
    "    # show image\n",
    "    plt.imshow(x_test_normalized[image_no].squeeze(), cmap=plt.cm.gray_r)\n",
    "    plt.show()\n",
    "    \n",
    "    # print prediction\n",
    "    print(model_prediction)\n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(10), model_prediction[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no = 952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.69011241e-06 4.86766960e-10 7.79238718e-09 8.99345765e-10\n",
      "  4.06367144e-06 1.11319727e-08 9.99992132e-01 1.77385289e-08\n",
      "  1.12906015e-07 1.35950522e-08]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_inference(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the model for the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tfl_model_file, x=x_test_normalized):\n",
    "    \n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    # model_input = model.tensor(model.get_input_details()[0][\"index\"])\n",
    "    # model_output = model.tensor(model.get_output_details()[0][\"index\"])\n",
    "    \n",
    "    predictions = np.empty((x_test_normalized.shape[0], 10), dtype=np.float32)\n",
    "    input_details, output_details = get_details(tfl_model_file)\n",
    "\n",
    "    \n",
    "    for index, data in enumerate(x_test_normalized):\n",
    "        input_data = [np.array(data, dtype=np.float32)]\n",
    "        model.set_tensor(input_details[0]['index'], input_data)\n",
    "        model.invoke()\n",
    "        output_data = model.get_tensor(output_details[0]['index'])\n",
    "        predictions[index] = output_data\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# original predictions\n",
    "tf_model_predictions = tf_model.predict(x_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "tfl_model_predictions = predict(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the predictions of the selected converted model to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Compare the result.\n",
    "try:\n",
    "    np.testing.assert_almost_equal(tf_model_predictions, tfl_model_predictions, decimal=10)\n",
    "except AssertionError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model accuracy and losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical crossentropy is the loss function which was used for training\n",
    "loss_fn_crossentropy = tf.keras.losses.CategoricalCrossentropy(reduction='sum_over_batch_size')\n",
    "\n",
    "loss_fn_meansquared = tf.keras.losses.MeanSquaredError(reduction='sum_over_batch_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function which calculates the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tfl_model_predictions, y=y_test):\n",
    "    accurate_count = 0\n",
    "\n",
    "    for index in range(len(tfl_model_predictions)):\n",
    "        if np.argmax(tfl_model_predictions[index]) == np.argmax(y[index]):\n",
    "            accurate_count += 1\n",
    "\n",
    "    model_accuracy = accurate_count * 1.0 / len(tfl_model_predictions)\n",
    "    \n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Lite Model Accuracy:\t\t 0.9813\n",
      "Original model accuracy:\t 0.9879000186920166\n",
      "TF Lite Model cross entropy loss:\t 0.072569594\n",
      "Original model cross entropy loss:\t 0.04126233980059624\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "tfl_model_accuracy = accuracy(tfl_model_predictions)\n",
    "tfl_crossentropy_loss = loss_fn_crossentropy(y_test, tfl_model_predictions).numpy()\n",
    "\n",
    "\n",
    "print(\"TF Lite Model Accuracy:\\t\\t\", tfl_model_accuracy)\n",
    "print('Original model accuracy:\\t', tf_model_accuracy)\n",
    "\n",
    "print(\"TF Lite Model cross entropy loss:\\t\", tfl_crossentropy_loss)\n",
    "print('Original model cross entropy loss:\\t', tf_model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
