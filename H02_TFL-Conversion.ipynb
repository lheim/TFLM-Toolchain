{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H02 Tensorflow Lite Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_model(tf_model, tf_model_file, quantization_type, representative_dataset, input_dt='float32', output_dt='float32', pure_int=False):\n",
    "\n",
    "    def yield_representative_dataset():\n",
    "      for x in representative_dataset:\n",
    "        yield [np.array([x], dtype=np.float32)]\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "\n",
    "    if input_dt == 'int8':\n",
    "        converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    if output_dt == 'int8':\n",
    "        converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "        \n",
    "    # foat32.\n",
    "    if quantization_type == 'none':\n",
    "        tflite_model = converter.convert()        \n",
    "        filename = './TFLite-model/' + get_tf_model_string(tf_model_file) + '_Q-none' + '.tflite'\n",
    "        open(filename, 'wb').write(tflite_model)\n",
    "        print(f'The model was sucessfully converted and written to {filename}.')\n",
    "        return filename\n",
    "    \n",
    "    elif quantization_type == 'mixed':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        filename = './TFLite-model/' + get_tf_model_string(tf_model_file) + '_Q-mixed' + '.tflite'\n",
    "        open(filename, 'wb').write(tflite_model)\n",
    "        print(f'The model was sucessfully converted, quantized and written to {filename}.')\n",
    "        return filename\n",
    "        \n",
    "        \n",
    "    elif quantization_type == 'full':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        \n",
    "        if pure_int:\n",
    "            # Note: The converter will throw an error\n",
    "            # if it encounters an operation it cannot currently quantize.\n",
    "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "            filename = './TFLite-model/' + get_tf_model_string(tf_model_file) + '_Q-full_IO-int8' + '.tflite'\n",
    "        else:\n",
    "            filename = './TFLite-model/' + get_tf_model_string(tf_model_file) + '_Q-full' + '.tflite'\n",
    "\n",
    "\n",
    "        \n",
    "        converter.representative_dataset = yield_representative_dataset\n",
    "        tflite_model = converter.convert()\n",
    "        open(filename, 'wb').write(tflite_model)\n",
    "        print(f'The model was sucessfully converted, quantized and written to {filename}.')\n",
    "        return filename\n",
    "\n",
    "    else:\n",
    "        print(\"Unkown quantization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfl_size(tfl_model_file, unquantized_model_file=None, gzip=False):\n",
    "    \n",
    "    if unquantized_model_file:\n",
    "        basic_model_size = os.path.getsize(unquantized_model_file) / 1024\n",
    "    else:\n",
    "        basic_model_size = os.path.getsize(tfl_model_file) / 1024\n",
    "    \n",
    "    \n",
    "    if gzip:\n",
    "        import zipfile\n",
    "        zipped_file = './keras-model/temp_zipped.zip'\n",
    "        with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "            f.write(tfl_model_file)\n",
    "        model_size = os.path.getsize(zipped_file) / 1024\n",
    "    else:\n",
    "        model_size = os.path.getsize(tfl_model_file) / 1024\n",
    "        \n",
    "    reduction = 100*((basic_model_size - model_size) / basic_model_size)\n",
    "    return model_size, reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfl_predict(tfl_model_file, x):\n",
    "    \n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    model_input = model.tensor(model.get_input_details()[0][\"index\"])\n",
    "    model_output = model.tensor(model.get_output_details()[0][\"index\"])\n",
    "    \n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "\n",
    "    # this might not be competly dynamic\n",
    "    predictions = np.empty((x.shape[0], output_details[0]['shape'][1]), dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    for index, data in enumerate(x):\n",
    "        input_data = np.array([data], dtype=np.float32)\n",
    "        model.set_tensor(input_details[0]['index'], input_data)\n",
    "        model.invoke()\n",
    "        output_data = model.get_tensor(output_details[0]['index'])\n",
    "        predictions[index] = output_data\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(tfl_model_predictions, y):\n",
    "    accurate_count = 0\n",
    "\n",
    "    for index in range(len(tfl_model_predictions)):\n",
    "        if np.argmax(tfl_model_predictions[index]) == np.argmax(y[index]):\n",
    "            accurate_count += 1\n",
    "\n",
    "    model_accuracy = accurate_count * 1.0 / len(tfl_model_predictions)\n",
    "    \n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfl_details(tfl_model_file):\n",
    "    \n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "\n",
    "    # input_shape = input_details[0]['shape']\n",
    "    # print(\"\\ninput_shape: \", input_shape)\n",
    "\n",
    "    # output_shape = output_details[0]['shape']\n",
    "    # print(\"\\noutput_shape: \", output_shape)\n",
    "\n",
    "    return input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfl_layer_details(tfl_model_file):\n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    \n",
    "    tensor_details = model.get_tensor_details()\n",
    "\n",
    "    return tensor_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfl_inference(tfl_model_file, input_data):\n",
    "\n",
    "    input_data = np.array([input_data], dtype=np.float32)\n",
    "\n",
    "    model = tf.lite.Interpreter(tfl_model_file)\n",
    "    model.allocate_tensors()\n",
    "    input_details, output_details = get_tfl_details(tfl_model_file)\n",
    "    model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    model.invoke()\n",
    "    model_prediction = model.get_tensor(output_details[0]['index'])\n",
    "    model.reset_all_variables()\n",
    "\n",
    "    # show image\n",
    "    plt.imshow(x_test_normalized[image_no].squeeze(), cmap=plt.cm.gray_r)\n",
    "    plt.show()\n",
    "    \n",
    "    # print prediction\n",
    "    print(model_prediction)\n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(10), model_prediction[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imported helper functions from H02_TFL-Conversion.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
